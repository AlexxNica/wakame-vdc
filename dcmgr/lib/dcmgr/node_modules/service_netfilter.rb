# -*- coding: utf-8 -*-
require 'isono'
require 'ipaddress'

module Dcmgr
  module NodeModules

    module NewDesign
      include Dcmgr::Helpers::NicHelper

      class Cache
        # Makes a call to the database and updates the Cache
        def update
          raise NotImplementedError
        end
        
        # Returns the cache
        # if _force_update_ is set to true, the cache will be updated from the database
        def get(force_update = false)
          raise NotImplementedError
        end
        
        # Adds a newly started instance to the existing cache
        def add_instance(inst_map)
          raise NotImplementedError
        end
        
        # Removes a terminated instance from the existing cache
        def remove_instance(inst_id)
          raise NotImplementedError
        end
      end
      
      class NetfilterCache < Cache
        def initialize(node)
          # Initialize the values needed to do rpc requests
          @node = node
          @rpc ||= Isono::NodeModules::RpcChannel.new(@node)
        end

        # Makes a call to the database and updates the Cache
        def update
          @cache = @rpc.request('hva-collector', 'get_netfilter_data', @node.node_id)
        end
        
        # Returns the cache
        # if _force_update_ is set to true, the cache will be updated from the database
        def get(force_update = false)
          self.update if @cache.nil? || force_update
          
          @cache
        end
        
        # Adds a newly started instance to the existing cache
        def add_instance(inst_map)
          if @cache.is_a? Array
            @cache << inst_map
          else
          
          end
        end
        
        # Removes a terminated instance from the existing cache
        def remove_instance(inst_id)
          
        end
      end
      
      class Rule
        #attr_accessor :rule
        
        #def initialize(rule = nil)
          #self.rule = rule
        #end
      end
      
      class IptablesRule < Rule
        attr_accessor :table
        attr_accessor :chain
        attr_accessor :rule
        # Should be either :incoming or :outgoing
        attr_accessor :bound
        attr_accessor :protocol
        
        def initialize(table = nil, chain = nil, protocol = nil, bound = nil, rule = nil)
          super()
          raise ArgumentError, "table does not exist: #{table}" unless NewDesign::IptablesPreMadeChains.keys.member?(table)
          self.table = table
          self.chain = chain
          self.protocol = protocol
          self.bound = bound
          self.rule = rule
        end
        
        def chain
          if NewDesign::IptablesPreMadeChains[self.table].member?(@chain)
            @chain.to_s.upcase 
          else
            @chain
          end
        end
      end

      class EbtablesRule < Rule
        attr_accessor :table
        attr_accessor :chain
        attr_accessor :rule
        # Should be either :incoming or :outgoing
        attr_accessor :bound
        attr_accessor :protocol
        
        def initialize(table = nil, chain = nil,  protocol = nil, bound = nil, rule = nil)
          super()
          raise ArgumentError, "table does not exist: #{table}" unless NewDesign::EbtablesPreMadeChains.keys.member?(table)
          self.table = table
          self.chain = chain
          self.protocol = protocol
          self.bound = bound
          self.rule = rule
        end
        
        def chain
          if NewDesign::EbtablesPreMadeChains[self.table].member?(@chain)
            @chain.to_s.upcase 
          else
            @chain
          end
        end
      end

      class Task
        #Must be an array of rules
        attr_accessor :rules
        
        def initialize
          @must_before = []
          @must_after = []
          @only_apply_if_exists = []
          @rules = []
        end
        
        # Returns an array of security group rules.
        # Every extending class needs to override this method to return its own rules
        # Commented out... let's use attr_accessor for this
        #def get_rules
          #[]
        #end
        
        def must_before(task = nil)
          unless task.nil?
            raise ArgumentError, "Not a task: #{task}." unless task.is_a?(Task)
            @must_before << task
          end
          @must_before
        end
        
        def must_after(task = nil)
          unless task.nil?
            raise ArgumentError, "Not a task: #{task}." unless task.is_a?(Task)
            @must_after << task
          end
          @must_after
        end
      end
      
      def self.eb_log(prefix)
        "--log-ip --log-arp --log-prefix '#{prefix}'"
      end
      
      # Drops all ARP packets coming into the host
      class DropArpToHost
        attr_reader :enable_logging
        attr_reader :log_prefix
        
        def initialize
          super()
          
          # Drop forwarding to host
          self.rules << EbtablesRule.new(:filter,:input,:arp,:outgoing,"--log-level 4 --log-ip --log-arp --log-prefix '#{self.log_prefix}' -j CONTINUE") if self.enable_logging
          self.rules << EbtablesRule.new(:filter,:input,:arp,:outgoing,"-j DROP")
        end
      end
      
      # Drops all ARP packet forwarding
      class DropArpForwarding
        attr_reader :enable_logging
        attr_reader :log_prefix
        
        def initialize(enable_logging,log_prefix)
          super()
          
          @enable_logging = enable_logging
          @log_prefix = log_prefix
          
          # Drop forwarding to other instances
          self.rules << EbtablesRule.new(:filter,:forward,:arp,:incoming,"--log-level 4 --log-ip --log-arp --log-prefix 'D d_#{self.log_prefix}_arp:' -j CONTINUE") if self.enable_logging
          self.rules << EbtablesRule.new(:filter,:forward,:arp,:incoming,"-j DROP")
        end
      end
      
      # Explicitely allows IP traffic between the gateway and the instances
      class AcceptIpToGateway
        attr_reader :gateway_ip
        
        def initialize(gateway_ip)
          super()
          
          @gateway_ip = gateway_ip
          
          self.rules << IptablesRule.new(:filter,:forward,nil,:incoming,"-s #{gateway_ip} -j ACCEPT")
        end
      end
      
      # Explicitely allows IP traffic between instances in the same security group
      class AcceptIpToSameGroup < Task
        attr_reader :friend_ips
        
        def initialize(friend_ips)
          super()
          
          @friend_ips = friend_ips
          
          friend_ips.each { friend_ip
            self.rules << IptablesRule.new(:filter,:forward,nil,:incoming,"-s #{friend_ip} -j ACCEPT")
          }
        end
      end
      
      # Explicitely allows ARP traffic between instances in the same security group
      class AllowARPToSameGroup
        attr_reader :inst_ip
        attr_reader :friend_ips
        attr_reader :enable_logging
        attr_reader :log_prefix
        
        def initialize(inst_ip,friend_ips,enable_logging,log_prefix)
          super()
          
          @enable_logging = enable_logging
          @log_prefix = log_prefix
          @inst_ip = inst_ip
          @friend_ips = friend_ips
          
          friend_ips.each { |friend_ip|
            # Log traffic
            self.rules << EbtablesRule.new(:filter,:forward,:arp,:incoming,"--protocol arp --arp-ip-src #{friend_ip} --arp-ip-dst #{self.inst_ip} --log-ip --log-arp --log-prefix '#{self.log_prefix}'       -j CONTINUE") if self.enable_logging
            self.rules << EbtablesRule.new(:filter,:forward,:arp,:incoming,"--protocol arp --arp-ip-src #{friend_ip} --arp-ip-dst #{self.inst_ip} -j ACCEPT")
          }
        end
      end
      
      # Explicitely allows ARP traffic to take place between the host and instance
      class AllowARPToHost < Task
        attr_reader :enable_logging
        attr_reader :log_prefix
        attr_reader :host_ip
        attr_reader :inst_ip
        
        def initialize(host_ip,inst_ip,enable_logging,log_prefix)
          super()
          
          @enable_logging = enable_logging
          @log_prefix = log_prefix
          @host_ip = host_ip
          @inst_ip = inst_ip
          
          self.rules << EbtablesRule.new(:filter,:input,:arp,:outgoing,"--protocol arp --arp-ip-src #{self.inst_ip} --arp-ip-dst #{self.host_ip} --log-ip --log-arp --log-prefix '#{self.log_prefix}' -j CONTINUE") if self.enable_logging
          self.rules << EbtablesRule.new(:filter,:input,:arp,:outgoing,"--protocol arp --arp-ip-src #{self.inst_ip} -j ACCEPT")
        end
      end
      
      # Implements VM isolation based on security groups
      # All direct traffic between instances in different
      # security groups will be blocked
      #class IsolateInstanceByGroup < Task
        #attr_reader :enable_logging
        #attr_reader :log_prefix
        #attr_reader :friend_ips
        #attr_reader :self_ip
      
        #def initialize(friend_ips,self_ip,enable_logging,log_prefix)
          #super()
        #end
      #end
      
      # Disables instances from spoofing another mac address
      class AntiMacSpoofing < Task
        attr_accessor :mac
        attr_accessor :enable_logging
        attr_accessor :log_prefix
        
        def initialize(mac,enable_logging,log_prefix)
        super()
        self.mac = mac
        self.enable_logging = enable_logging
        self.log_prefix = log_prefix
        
        # Prevent spoofing to the outside world
        self.rules << EbtablesRule.new(:filter,:forward,:arp,:outgoing,"--protocol arp --arp-mac-src ! #{self.mac} #{NewDesign::eb_log(self.log_prefix) if self.enable_logging} -j DROP")
        # Prevent spoofing to the host
        self.rules << EbtablesRule.new(:filter,:input,:arp,:outgoing,"--protocol arp --arp-mac-src ! #{self.mac} #{NewDesign::eb_log(self.log_prefix) if self.enable_logging} -j DROP")
        end
      end
      
      # Disable instances from spoofing another ip address
      class AntiIpSpoofing < Task
        attr_accessor :ip
        attr_accessor :enable_logging
        attr_accessor :log_prefix
        
        def initialize(ip,enable_logging,log_prefix)
        super()
        self.ip = ip
        self.enable_logging = enable_logging
        self.log_prefix = log_prefix
        
        # Prevent spoofing to the outside world
        self.rules << EbtablesRule.new(:filter,:forward,:arp,:outgoing,"--protocol arp --arp-ip-src ! #{self.ip} #{NewDesign::eb_log(self.log_prefix) if self.enable_logging} -j DROP")
        # Prevent spoofing to the host
        self.rules << EbtablesRule.new(:filter,:input,:arp,:outgoing,"--protocol arp --arp-ip-src ! #{self.ip} #{NewDesign::eb_log(self.log_prefix) if self.enable_logging} -j DROP")
        
        # Prevent the outside world from spoofing to the instance
        self.rules << EbtablesRule.new(:filter,:forward,:arp,:incoming,"--protocol arp --arp-ip-dst ! #{self.ip} #{NewDesign::eb_log(self.log_prefix) if self.enable_logging} -j DROP")
        # Prevent the host from spoofing to the instance
        self.rules << EbtablesRule.new(:filter,:output,:arp,:incoming,"--protocol arp --arp-ip-dst ! #{self.ip} #{NewDesign::eb_log(self.log_prefix) if self.enable_logging} -j DROP")
        end
      end
      
      class AllowArpBroadcast < Task
        attr_accessor :hva_ip
        
        def initialize(hva_ip,enable_logging = false,log_prefix = nil)
          super()
          self.hva_ip = hva_ip
        
          # Allow broadcast from the network
          self.rules << EbtablesRule.new(:filter,:forward,:arp,:incoming,"--protocol arp --arp-mac-dst 00:00:00:00:00:00 #{NewDesign::eb_log(log_prefix) if enable_logging} -j ACCEPT")
          # Allow broadcast from the host
          self.rules << EbtablesRule.new(:filter,:output,:arp,:outgoing,"--protocol arp --arp-ip-src=#{self.hva_ip} #{NewDesign::eb_log(log_prefix) if enable_logging} --arp-mac-dst 00:00:00:00:00:00 -j ACCEPT")
        end
      end
      
      # Contains specific rules for ip addresses to which connections should
      # not be natted.
      class ExcludeNat < Task
        #An array of the ip addresses excluded from nat
        attr_accessor :excluded_ips
        
        def initialize(ips,self_ip)
          super()
          raise ArgumentError, "ips Must be an array containing IP addresses" unless ips.is_a? Array
          
          ips.each { |ip|
            if ip.is_a? String
              exclude = IPAddress(ip)
            elsif ip.is_a? IPAddress
              exclude = ip
            else
              next
            end
            
            self.rules << IptablesRule.new(:nat,:prerouting,nil,nil,"-d #{self_ip.address} -s #{ip.address} -j ACCEPT")
            self.rules << IptablesRule.new(:nat,:postrouting,nil,nil,"-d #{ip.address} -s #{self_ip.address} -j ACCEPT")
          }
        end
      end
      
      # Contains specific rules for ip addresses to which connections should
      # not be natted. Depends on the netfilter IpSet module
      class ExcludeNatIpSet < Task
        attr_accessor :excluded_ips
      end
      
      class StaticNatLog < Task
        attr_accessor :inside_ip
        attr_accessor :outside_ip
        attr_accessor :snat_log_prefix
        attr_accessor :dnat_log_prefix
        
        def initialize(inside_ip,outside_ip,snat_log_prefix = "",dnat_log_prefix = "")
          super()
          
          self.inside_ip = inside_ip
          self.outside_ip = outside_ip
          self.snat_log_prefix = snat_log_prefix
          self.dnat_log_prefix = dnat_log_prefix
          
          self.rules = []
          self.rules << IptablesRule.new(:nat,:prerouting,nil,nil,"-d #{self.outside_ip} -j LOG --log-prefix '#{self.dnat_log_prefix}'")
          self.rules << IptablesRule.new(:nat,:postrouting,nil,nil,"-s #{self.inside_ip} -j LOG --log-prefix '#{self.snat_log_prefix}'")
          @must_before << StaticNat
        end
      end
      
      class StaticNat < Task
        attr_accessor :inside_ip
        attr_accessor :outside_ip
        attr_accessor :mac_address
        
        def initialize(inside_ip, outside_ip, mac_address)
          super()
          
          self.inside_ip = inside_ip
          self.outside_ip = outside_ip
          self.mac_address = mac_address
          
          self.rules = []
          
          self.rules << EbtablesRule.new(:nat,:prerouting,nil,:incoming,"-p arp --arp-ip-dst #{self.outside_ip} --arp-opcode REQUEST -j arpreply --arpreply-mac #{self.mac_address}")
          self.rules << IptablesRule.new(:nat,:postrouting,nil,:outgoing,"-s #{self.inside_ip} -j SNAT --to #{self.outside_ip}")
          self.rules << IptablesRule.new(:nat,:prerouting,nil,:incoming,"-d #{self.outside_ip} -j DNAT --to #{self.inside_ip}")
        end
      end
      
      class SecurityGroup < Task
      
      end
      
      # Drop all incoming IP layer traffic
      class DropIncomingIpTraffic < Task
        def initialize
          [:icmp,:tcp,:udp].each { |protocol|
            self.rules << IptablesRule.new(:filter,:forward,protocol,:incoming,"-p #{protocol} -j DROP")
          }
        end
      end
      
      # Allows any outgoing IP layer traffic from the instance to pass through
      class AllowOutgoingIpTraffic < Task
        def initialize
          [:icmp,:tcp,:udp].each { |protocol|
            self.rules << IptablesRule.new(:filter,:forward,protocol,:outgoing,"-p #{protocol} -j ACCEPT")
          }
        end
      end
      
      # Allows for DNS traffic to be exchanged with and only with Wakame's DNS server
      class DNS < Task
        #TODO: allow ARP traffic to DNS server
        attr_reader :dns_server_ip
        attr_reader :dns_server_port
        
        def initialize(dns_server_ip,dns_server_port="53")
          super()
          
          @dns_server_ip = dns_server_ip
          @dns_server_port = dns_server_port
          
          # Allow DNS traffic to take place
          self.rules << IptablesRule.new(:filter,:forward,:udp,:outgoing,"-p udp -d #{self.dns_server_ip} --dport #{self.dns_server_port} -j ACCEPT")
          
          # Disable any non DNS traffic to DNS server
          [:udp,:tcp,:icmp].each { |protocol|
            self.rules << IptablesRule.new(:filter,:forward,protocol,:outgoing,"-d #{self.dns_server_ip} -p #{protocol} -j DROP")
          }
        end
      end
      
      class TranslateMetadataAddress < Task
        #TODO: allow ARP traffic to metadata server... perhaps I should do this in the ARP based VM isolation
        attr_reader :metadata_ip
        attr_reader :metadata_port
        attr_reader :metadata_fake_ip
        attr_reader :metadata_fake_port
        
        def initialize(metadata_ip,metadata_port,metadata_fake_ip = "169.254.169.254",metadata_fake_port = "80")
          super()
          
          @metadata_ip = metadata_ip
          @metadata_port = metadata_port
          @metadata_fake_ip = metadata_fake_ip
          @metadata_fake_port = metadata_fake_port
          
          # Translate requests to the metadata server
          self.rules << IptablesRule.new(:nat,:prerouting,:tcp,nil,"-d #{self.metadata_fake_ip} -p tcp --dport #{self.metadata_fake_port} -j DNAT --to-destination #{self.metadata_ip}:#{self.metadata_port}")
          # Accept tcp traffic to the metadata server
          self.rules << IptablesRule.new(:filter,:forward,:tcp,:outgoing,"-p tcp -d #{self.metadata_ip} --dport #{self.metadata_port} -j ACCEPT")
        end
      end
      
      # Allows for DHCP traffic to take place with and only with wakame's DHCP server
      class DHCP < Task
        #TODO: allow ARP traffic to DHCP server
        attr_reader :dhcp_server_ip
        
        def initialize(dhcp_server_ip)
          super()
          
          @dhcp_server_ip = dhcp_server_ip
          
          # Block DHCP replies that aren't coming from our DHCP server
          self.rules << IptablesRule.new(:filter,:forward,:udp,:incoming,"-p udp ! -s #{self.dhcp_server_ip} --sport 67 -j DROP")
          self.rules << IptablesRule.new(:filter,:forward,:udp,:incoming,"-p udp ! -s #{self.dhcp_server_ip} --sport 68 -j DROP")
          
          # Accept DHCP replies coming from our DHCP server
          self.rules << IptablesRule.new(:filter,:forward,:udp,:incoming,"-p udp -s #{self.dhcp_server_ip} --sport 67 -j ACCEPT")
          self.rules << IptablesRule.new(:filter,:forward,:udp,:incoming,"-p udp -s #{self.dhcp_server_ip} --sport 68 -j ACCEPT")
          
          # Drop all non DHCP traffic to our DHCP server
          [:udp,:tcp,:icmp].each { |protocol|
            self.rules << IptablesRule.new(:filter,:forward,protocol,:outgoing,"-d #{self.dhcp_server_ip} -p #{protocol} -j DROP")
          }
        end
      end
      
      # Accept all related and established TCP connections
      class AcceptTcpRelatedEstablished < Task
        def initialize
          super()
          self.rules << IptablesRule.new(:filter,:forward,:tcp,nil,"-m state --state RELATED,ESTABLISHED -p tcp -j ACCEPT")
        end
      end
      
      class AcceptIcmpRelatedEstablished < Task
        def initialize
          super()
          self.rules << IptablesRule.new(:filter,:forward,:tcp,nil,"-m state --state RELATED,ESTABLISHED -p icmp -j ACCEPT")
        end
      end
      
      class AcceptUdpRelatedEstablished < Task
        def initialize
          super()
          self.rules << IptablesRule.new(:filter,:forward,:tcp,nil,"-m state --state ESTABLISHED -p udp -j ACCEPT")
        end
      end
      
      # via http://backreference.org/2010/06/11/iptables-debugging/
      # To debug ipv4 packets.
      # $ sudo tail -F /var/log/kern.log | grep TRACE:
      class DebugIptables < Task
        def initialize
          super()
          self.rules << IptablesRule.new(:raw,:output,:icmp,:outgoing,"-p icmp -j TRACE")
          self.rules << IptablesRule.new(:raw,:prerouting,:icmp,:incoming,"-p icmp -j TRACE")
        end
      end
      
      class Chain
        attr_reader :name
        attr_reader :table
        
        def initialize(table,name)
          @table = table
          @name = name
        end
      end
      
      IptablesPreMadeChains = {
          :filter => [:input,:output,:forward],
          :nat => [:prerouting,:postrouting,:output],
          :mangle => [:prerouting,:output,:input,:postrouting],
          :raw => [:prerouting, :output]
      }
      
      class IptablesChain < Chain
        def initialize(table,name)
          raise ArgumentError, "table #{table} doesn't exist. Existing tables are '#{NewDesign::IptablesPreMadeChains.keys.join(",")}'." unless NewDesign::IptablesPreMadeChains.keys.member?(table)
          raise ArgumentError, "name can not be any of the following: '#{NewDesign::IptablesPreMadeChains[table].join(",")}'." if NewDesign::IptablesPreMadeChains[table].member?(name)
          
          super
        end
      end
      
      EbtablesPreMadeChains = {
          :filter => [:input,:output,:forward],
          :nat => [:prerouting,:postrouting,:output],
          :broute => [:brouting]
      }
      
      class EbtablesChain < Chain
        def initialize(table,name)
          raise ArgumentError, "table #{table} doesn't exist. Existing tables are '#{NewDesign::EbtablesPreMadeChains.keys.join(",")}'." unless NewDesign::EbtablesPreMadeChains.keys.member?(table)
          raise ArgumentError, "name can not be any of the following: '#{NewDesign::EbtablesPreMadeChains[table].join(",")}'." if NewDesign::EbtablesPreMadeChains[table].member?(name)
          
          super
        end
      end

      class TaskFactory
        #Returns the netfilter tasks required for this vnic
        def self.create_tasks_for_vnic(vnic,node)
          tasks = []
          return tasks
          # Nat tasks
          #TODO: handle is_natted? properly
          #if is_natted? vnic
          unless vnic[:ipv4][:nat_address].nil?
            tasks << StaticNatLog.new(vnic.inside_ip, vnic.inside_ip, "SNAT #{vnic[:uuid]}", "DNAT #{vnic[:uuid]}") if node.manifest.config.packet_drop_log
            tasks << StaticNat.new(vnic.inside_ip, vnic.inside_ip, vnic.mac_address)
          end
          
          gw_addr = Isono::Util.default_gw_ipaddr
          enable_logging = node.manifest.config.packet_drop_log
          
          # Ebtables tasks
          tasks << AllowArpBroadcast.new(gw_addr,enable_logging,"A arp bc #{vnic[:uuid]}: ")
          tasks << AntiIpSpoofing.new(vnic.inside_ip,enable_logging,"D arp sp #{vnic[:uuid]}: ")
          tasks << AntiMacSpoofing.new(vnic.mac_address,enable_logging,"D ip sp #{vnic[:uuid]}: ")
          
          tasks << AllowARPToHost.new(gw_addr,vnic.inside_ip,enable_logging,"A arp to_host #{vnic[:uuid]}")
          
          # VM isolation based on same security group
          #tasks << AllowARPToSameGroup.new(inst_ip,friend_ips,enable_logging,"A arp to_friend #{vnic.uuid}") # <--- constructor values not filled in yet
          
          tasks
        end
      end
      
      # Abstract class for TaskManager's to extend
      # A taskmanager should be able to understand certain rules in a task and be able to apply those
      class TaskManager
        #attr_reader :applied_tasks
      
        #def initialize
          #super
          #@applied_tasks = []
        #end
        
        def apply_task(task)
          #raise ArgumentError, "#{task} is not a Task." unless task.is_a? Task
          #@applied_tasks << task
        end
        
        def apply_tasks(tasks)
          raise ArgumentError, "tasks must be an Array of Tasks." unless tasks.is_a?(Array)
          tasks.each { |task|
            next unless task.is_a?(Task)
            apply_task(task)
          }
        end
        
        def remove_task(task)
          #raise ArgumentError, "#{task} is not a Task." unless task.is_a? Task
          #raise "#{task} is not applied." unless @applied_tasks.member?(task)
          
          #@applied_tasks.delete(task)
        end
        
        def remove_tasks(tasks)
          raise ArgumentError, "tasks must be an Array of Tasks." unless tasks.is_a?(Array)
          tasks.each { |task|
            next unless task.is_a?(Task)
            remove_task(task)
          }
        end
      end
      
      # Abstract class for task managers that apply tasks by vnic to expend
      # This is for task managers that want to apply tasks differently depending on which
      # vnic they're associated with.
      class VnicTaskManager < TaskManager        
        #def intialize
          #super
          #@applied_vnics = []
        #end
        
        def apply_vnic_tasks(vnic_map,tasks)
          #apply_tasks(tasks)
        end
        
        # Should remove _tasks_ for this specific vnic if they are applied
        # If no _tasks_ argument is provided, it should remove all tasks for this vnic
        def remove_vnic_tasks(vnic_map,tasks = nil)
          #remove_tasks(tasks)
        end
      end
      
      # Task manager that creates chains based on vif uuid and protocol
      # Supports ebtables rules and iptables rules
      class VNicProtocolTaskManager < VnicTaskManager
        include Dcmgr::Helpers::NicHelper
        # These store the protocols used by iptables and ebtables
        attr_reader :iptables_protocols
        attr_reader :ebtables_protocols
        # These are flags that decide whether or not iptables and ebtables are enabled
        attr_accessor :enable_iptables
        attr_accessor :enable_ebtables
        # Flag that decides whether or not we output commands that are applied
        attr_accessor :verbose_commands
        #attr_accessor :applied_chains
        
        def initialize
          super
          @iptables_protocols = {
              'tcp'  => 'tcp',
              'udp'  => 'udp',
              'icmp' => 'icmp',
            }
          @ebtables_protocols = {
              'ip4'  => 'ip4',
              'arp'  => 'arp',
              #'ip6'  => 'ip6',
              #'rarp' => '0x8035',
            }
        end
        
        def iptables_chains(vnic_map)
          chains = []
          
          [ 's', 'd' ].each { |bound|
            self.iptables_protocols.each { |k,v|
                chains << IptablesChain.new(:filter, "#{bound}_#{vnic_map[:uuid]}")
                chains << IptablesChain.new(:filter, "#{bound}_#{vnic_map[:uuid]}_#{k}")

                chains << IptablesChain.new(:filter, "#{bound}_#{vnic_map[:uuid]}_drop")
                chains << IptablesChain.new(:filter, "#{bound}_#{vnic_map[:uuid]}_#{k}_drop")
            }
            
            # Only create the NAT chains if the vnic is in fact natted
            chains << IptablesChain.new(:nat, "#{bound}_#{[:uuid]}") if is_natted? vnic_map
          }
          
          chains
        end
        
        def iptables_forward_chain_jumps(vnic)
          jumps = []
          
          #Main jumps from the forward chains
          jumps << IptablesRule.new(:filter,:forward,nil,nil,"-m physdev --physdev-is-bridged --physdev-in  #{vnic[:uuid]} -j s_#{vnic[:uuid]}")
          jumps << IptablesRule.new(:filter,:forward,nil,nil,"-m physdev --physdev-is-bridged --physdev-out #{vnic[:uuid]} -j d_#{vnic[:uuid]}")
          
          jumps
        end
        
        def iptables_protocol_chain_jumps(vnic)
          jumps = []
          
          [ 's', 'd' ].each do |bound|
            self.iptables_protocols.each { |k,v|
              case k
              when 'tcp'
                case bound
                when 's'
                  jumps << IptablesRule.new(:filter,"#{bound}_#{vnic[:uuid]}",nil,:outgoing,"-m state --state NEW,ESTABLISHED -p #{k} -j #{bound}_#{vnic[:uuid]}_#{k}")
                when 'd'
                  jumps << IptablesRule.new(:filter,"#{bound}_#{vnic[:uuid]}",nil,:incoming,"-p #{k} -j #{bound}_#{vnic[:uuid]}_#{k}")
                end
              when 'udp'
                case bound
                when 's'
                  jumps << IptablesRule.new(:filter,"#{bound}_#{vnic[:uuid]}",nil,:outgoing,"-m state --state NEW,ESTABLISHED -p #{k} -j #{bound}_#{vnic[:uuid]}_#{k}")
                when 'd'
                  jumps << IptablesRule.new(:filter,"#{bound}_#{vnic[:uuid]}",nil,:incoming,"-p #{k} -j #{bound}_#{vnic[:uuid]}_#{k}")
                end
              when 'icmp'
                case bound
                when 's'
                  jumps << IptablesRule.new(:filter,"#{bound}_#{vnic[:uuid]}",nil,:outgoing,"-m state --state NEW,ESTABLISHED,RELATED -p #{k} -j #{bound}_#{vnic[:uuid]}_#{k}")
                when 'd'
                  jumps << IptablesRule.new(:filter,"#{bound}_#{vnic[:uuid]}",nil,:incoming,"-p #{k} -j #{bound}_#{vnic[:uuid]}_#{k}")
                end
              end
            }
          end
          
          jumps
        end
        
        def iptables_nat_chain_jumps(vnic)
          jumps = []
          
          jumps << IptablesRule.new(:nat,:prerouting,nil,nil,"-d #{vnic[:ipv4][:nat_address]} -j d_#{vnic[:uuid]}")
          jumps << IptablesRule.new(:nat,:postrouting,nil,nil,"-s #{vnic[:ipv4][:address]} -j s_#{vnic[:uuid]}")
          
          jumps
        end
        
        def ebtables_chains(vnic)
          chains = []
          
          chains << EbtablesChain.new(:filter, "s_#{vnic[:uuid]}")
          chains << EbtablesChain.new(:filter, "d_#{vnic[:uuid]}")
          chains << EbtablesChain.new(:filter, "s_#{vnic[:uuid]}_d_hst")
          chains << EbtablesChain.new(:filter, "d_#{vnic[:uuid]}_s_hst")
          self.ebtables_protocols.each { |k,v|
            chains << EbtablesChain.new(:filter, "s_#{vnic[:uuid]}_#{k}")
            chains << EbtablesChain.new(:filter, "d_#{vnic[:uuid]}_#{k}")
            chains << EbtablesChain.new(:filter, "s_#{vnic[:uuid]}_d_hst_#{k}")
            chains << EbtablesChain.new(:filter, "d_#{vnic[:uuid]}_s_hst_#{k}")
          }
          
          chains
        end
        
        def ebtables_forward_chain_jumps(vnic)
          jumps = []
          
          jumps << EbtablesRule.new(:filter,:forward,nil,nil,"-i #{vnic[:uuid]} -j s_#{vnic[:uuid]}")
          jumps << EbtablesRule.new(:filter,:forward,nil,nil,"-o #{vnic[:uuid]} -j d_#{vnic[:uuid]}")
          
          jumps
        end
        
        def ebtables_protocol_chain_jumps(vnic)
          jumps = []
          
          self.ebtables_protocols.each { |k,v|
            jumps << EbtablesRule.new(:filter,"s_#{vnic[:uuid]}",nil,:outgoing,"-p #{v} -j s_#{vnic[:uuid]}_#{k}")
            jumps << EbtablesRule.new(:filter,"d_#{vnic[:uuid]}",nil,:incoming,"-p #{v} -j d_#{vnic[:uuid]}_#{k}")
            jumps << EbtablesRule.new(:filter,"s_#{vnic[:uuid]}_d_hst",nil,:outgoing,"-p #{v} -j s_#{vnic[:uuid]}_d_hst_#{k}")
            jumps << EbtablesRule.new(:filter,"d_#{vnic[:uuid]}_s_hst",nil,:incoming,"-p #{v} -j d_#{vnic[:uuid]}_s_hst_#{k}")
          }
          
          jumps
        end
        
        def ebtables_input_chain_jumps(vnic)
          jumps = []
          
          jumps << EbtablesRule.new(:filter,:input,nil,:outgoing,"-i #{vnic[:uuid]} -j s_#{vnic[:uuid]}_d_hst")
          
          jumps
        end
        
        def ebtables_output_chain_jumps(vnic)
          jumps = []
          
          jumps << EbtablesRule.new(:filter,:output,nil,:incoming,"-o #{vnic[:uuid]} -j d_#{vnic[:uuid]}_s_hst")
          
          jumps
        end
        
        #Returns commands for creating iptables chains and their jump rules
        def get_iptables_chains_apply_commands(vnic_map)
          commands = []
          
          commands << iptables_chains(vnic_map).map { |chain| "iptables -t #{chain.table} -N #{chain.name}"}
          
          create_jump_block = Proc.new { |jump| 
            "iptables -t #{jump.table} -A #{jump.chain} #{jump.rule}"
          }
          
          commands << iptables_forward_chain_jumps(vnic_map).map(&create_jump_block)
          commands << iptables_nat_chain_jumps(vnic_map).map(&create_jump_block) if is_natted? vnic_map
          commands << iptables_protocol_chain_jumps(vnic_map).map(&create_jump_block)
          
          commands.flatten.uniq
        end
        
        # Apply the custom iptables chains for this vnic
        # This method only applies the chains and doesn't make any rules
        def apply_iptables_chains(vnic_map)
          cmds = get_iptables_chains_apply_commands(vnic_map)
          puts cmds.join("\n") if self.verbose_commands
          system(cmds.join("\n"))
        end
        
        def remove_iptables_chains(vnic)
          cmds = get_iptables_chains_remove_commands(vnic)
          puts cmds.join("\n") if self.verbose_commands
          system(cmds.join("\n"))
        end
        
        def get_iptables_chains_remove_commands(vnic_map)
          commands = []
          
          delete_jump_block = Proc.new {|jump| "iptables -t #{jump.table} -D #{jump.chain} #{jump.rule}"}
          
          commands << iptables_forward_chain_jumps(vnic_map).map(&delete_jump_block)
          commands << iptables_nat_chain_jumps(vnic_map).map(&delete_jump_block) if is_natted?(vnic_map)
          
          commands << iptables_chains(vnic_map).map {|chain| 
            ["iptables -t #{chain.table} -F #{chain.name}","iptables -t #{chain.table} -X #{chain.name}"]
          }
          
          commands.flatten.uniq
        end
        
        def apply_ebtables_chains(vnic_map)
          cmds = get_ebtables_chains_apply_commands(vnic_map)
          puts cmds.join("\n") if self.verbose_commands
          system(cmds.join("\n"))
        end
        
        def get_ebtables_chains_apply_commands(vnic_map)
          commands = []
          
          commands << ebtables_chains(vnic_map).map {|chain| ["ebtables -t #{chain.table} -N #{chain.name}","ebtables -t #{chain.table} -P #{chain.name} DROP"]}
          
          create_jump_block = Proc.new {|jump| "ebtables -t #{jump.table} -A #{jump.chain} #{jump.rule}"}
          
          commands << ebtables_forward_chain_jumps(vnic_map).map(&create_jump_block)
          commands << ebtables_input_chain_jumps(vnic_map).map(&create_jump_block)
          commands << ebtables_output_chain_jumps(vnic_map).map(&create_jump_block)
          commands << ebtables_protocol_chain_jumps(vnic_map).map(&create_jump_block)
          
          commands.flatten.uniq
        end
        
        def remove_ebtables_chains(vnic)
          cmds = get_ebtables_chains_remove_commands(vnic)
          puts cmds.join("\n") if self.verbose_commands
          system(cmds.join("\n"))
        end
        
        def get_ebtables_chains_remove_commands(vnic_map)
          commands = []
          
          delete_jump_block = Proc.new {|jump| "ebtables -t #{jump.table} -D #{jump.chain} #{jump.rule}"}
          
          commands << ebtables_forward_chain_jumps(vnic_map).map(&delete_jump_block)
          commands << ebtables_input_chain_jumps(vnic_map).map(&delete_jump_block)
          commands << ebtables_output_chain_jumps(vnic_map).map(&delete_jump_block)
          
          commands << ebtables_chains(vnic_map).map {|chain|
            ["ebtables -t #{chain.table} -F #{chain.name}","ebtables -t #{chain.table} -X #{chain.name}"]
          }
          
          commands.flatten.uniq
        end
        
        # Jumps to custom chains named after the vnic's uuid,
        # then jumps to more custom chains based on the protocol used.
        # In those the real netfiltering happens
        def apply_vnic_tasks(vnic_map, tasks)
          apply_iptables_chains(vnic_map) if self.enable_iptables
          apply_ebtables_chains(vnic_map) if self.enable_ebtables
          
          # Apply the tasks to our chains
          apply_tasks(tailor_vnic_chains(vnic_map,tasks))
        end
        
        # Translates _rule_ into a command that can be directly passed on to the OS
        # _action_ determines if the command must _:apply_ or _:remove_ a rule. 
        def get_rule_command(rule,action)
          actions = {:apply => "A", :remove => "D"}
          raise ArgumentError, "#{rule} is not a Rule" unless rule.is_a? Rule
          raise ArgumentError, "action must be one of the following: '#{actions.keys.join(",")}'" unless actions.member? action
          
          if rule.is_a?(IptablesRule) && self.enable_iptables
            "iptables -t #{rule.table} -#{actions[action]} #{rule.chain} #{rule.rule}"
          elsif rule.is_a?(EbtablesRule) && self.enable_ebtables
            "ebtables -t #{rule.table} -#{actions[action]} #{rule.chain} #{rule.rule}"
          else
            nil
          end
        end
        
        def apply_tasks(tasks)
          commands = []

          commands = tasks.map { |task|
            next unless task.is_a? Task
            task.rules.map { |rule|
              next unless rule.is_a? Rule
              get_rule_command(rule,:apply)
            }
          }
          
          final_commands = commands.flatten.uniq.compact
          puts final_commands.join("\n") if self.verbose_commands
          
          system(final_commands.join("\n"))
        end
        
        def remove_tasks(tasks)
          commands = []
          
          commands = tasks.map { |task|
            next unless task.is_a? Task
            rules.map { |rule|
              get_rule_command(rule,:remove)
            }
          }
          
          final_commands = commands.flatten.uniq.compact
          puts final_commands.join("\n") if self.verbose_commands
          
          system(final_commands.join("\n"))
        end
        
        # Returns a new set of tasks with their chains matched to this manager's model
        def tailor_vnic_chains(vnic,tasks)
          bound = {:incoming => "d", :outgoing => "s"}

          tasks.each { |task|
            task.rules.each { |rule|
              if rule.is_a?(IptablesRule) && self.enable_iptables
                case rule.table
                  when :nat
                    case rule.chain
                      when :prerouting.to_s.upcase then
                        rule.chain = "d_#{vnic[:uuid]}"
                      when :postrouting.to_s.upcase then
                        rule.chain = "s_#{vnic[:uuid]}"
                    end
                  when :filter
                    case rule.chain
                      when :forward.to_s.upcase then
                        rule.chain = "d_#{vnic[:uuid]}"
                    end
                end
              elsif rule.is_a?(EbtablesRule) && self.enable_ebtables
                case rule.table
                  when :filter then
                    case rule.chain
                      when :input.to_s.upcase then
                        rule.chain = "s_#{vnic[:uuid]}_d_hst_#{rule.protocol}"
                      when :output.to_s.upcase then
                        rule.chain = "d_#{vnic[:uuid]}_s_hst_#{rule.protocol}"
                      when :forward.to_s.upcase then
                        rule.chain = "#{bound[rule.bound]}_#{vnic[:uuid]}_#{rule.protocol}"
                    end
                end
              end
            }
          }
        end
        
        # Removes _tasks_ for this specific vnic if they are applied
        # If no _tasks_ argument is provided, all tasks for this vnic will be removed
        def remove_vnic_tasks(vnic,tasks = nil)
          if tasks.nil?
            remove_iptables_chains(vnic) if self.enable_iptables
            remove_ebtables_chains(vnic) if self.enable_ebtables
          else
            remove_tasks(tailor_vnic_chains(vnic,tasks))
          end
        end
        
        def apply_task(task)
          #super(task)
          task.get_rules.each { |rule|
            if rule.is_a? EbtablesRule  && self.enable_ebtables
              apply_ebtables_rule(rule)
            elsif rule.is_a? IptablesRule && self.enable_iptables
              apply_iptables_rule(rule)
            end
          }
        end
        
        def remove_task(task)
          #super(task)
          task.get_rules.each { |rule|
            if rule.is_a? EbtablesRule && self.enable_ebtables
              apply_ebtables_rule(rule)
            elsif rule.is_a? IptablesRule && self.enable_iptables
              apply_iptables_rule(rule)
            end
          }
        end
      end
      
      # A controller interface to be implemented
      class Controller
        def apply_instance(instance)
          #TODO: properly put together the instance object if it's a uuid or inst_map passed
          raise ArgumentError, "#{instance} must be an Instance." unless instance.is_a?(Instance)
        end
        
        def remove_instance(instance)
          raise ArgumentError, "#{instance} must be an Instance." unless instance.is_a?(Instance)
        end
        
        def join_security_group(instance,group)
          raise ArgumentError, "#{instance} must be an Instance." unless instance.is_a?(Instance)
          raise ArgumentError, "#{group} must be a SecurityGroup." unless instance.is_a?(SecurityGroup)
        end
        
        def leave_security_group(instance,group)
          raise ArgumentError, "#{instance} must be an Instance." unless instance.is_a?(Instance)
          raise ArgumentError, "#{group} must be a SecurityGroup." unless instance.is_a?(SecurityGroup)
        end
        
        def update_security_group(group)
          raise ArgumentError, "#{group} must be a SecurityGroup." unless instance.is_a?(SecurityGroup)
        end
      end
      
      class TaskManagerFactory
        def self.create_task_manager(node)
          manager = VNicProtocolTaskManager.new
          manager.enable_ebtables = node.manifest.config.enable_ebtables
          manager.enable_iptables = node.manifest.config.enable_iptables
          manager.verbose_commands = node.manifest.config.verbose_netfilter
          
          manager
        end
      end
      
      class NetfilterController < NewDesign::Controller
        attr_accessor :task_manager
        attr_reader :node
        
        # This controller should use a cache
        
        def initialize(node)
          super()
          @node = node
          
          @cache = NetfilterCache.new(@node)
          
          self.task_manager = TaskManagerFactory.create_task_manager(node)
          raise "#{self.task_manager} must be a VnicTaskManager" unless self.task_manager.is_a?(VnicTaskManager)
          
          # Initialize Netfilter configuration
          cmds = []
          cmds << init_iptables if node.manifest.config.enable_iptables
          cmds << init_ebtables if node.manifest.config.enable_ebtables
          cmds.flatten! 
            
          puts cmds.join("\n") if node.manifest.config.verbose_netfilter
          system(cmds.join("\n"))
          
          self.task_manager.apply_tasks([DebugIptables.new]) if node.manifest.config.debug_iptables
          
          #p @cache.get
          
          # Apply the current instances if there are any
          @cache.get[:instances].each { |inst_map|
            self.apply_instance(inst_map)
          }
        end
        
        def apply_instance(instance)
          if instance.is_a? String
            # We got a uuid. Find it in the cache.
            inst_map = @cache.get[:instances].find { |inst| inst[:uuid] == instance}

            # If we couldn't find this instance's uuid in the cache, we update the cache and try again
            if inst_map.nil?
              @cache.update
              inst_map = @cache.get[:instances].find { |inst| inst[:uuid] == instance}
            end
          elsif
            #TODO: When we get something other than a String, make sure it's a Hash
            inst_map = instance
          end
          
          # Call the factory to create all tasks for each vnic. Then apply them
          inst_map[:vif].each { |vnic|
            self.task_manager.apply_vnic_tasks(vnic,TaskFactory.create_tasks_for_vnic(vnic,node))
          }
        end
        
        def remove_instance(inst_id)
          # Call the factory to create all tasks for each vnic. Then remove them
          inst_map = @cache.get[:instances].find { |inst| inst[:uuid] == inst_id}
          
          inst_map[:vif].each { |vnic|
            #TODO: Check if it's really necessary to call the task factory here
            #self.task_manager.remove_vnic_tasks(vnic,TaskFactory.create_tasks_for_vnic(vnic,node))
            self.task_manager.remove_vnic_tasks(vnic)
          }
        end
        
        def join_security_group(instance,group)
          super
        end
        
        def leave_security_group(instance,group)
          super
        end
        
        def update_security_group(group)
          super
        end
        
        private
        def init_iptables
          [
            "iptables -t nat -F",
            "iptables -t nat -X",
            "iptables -t nat -Z",
            "iptables -t filter -F",
            "iptables -t filter -X",
            "iptables -t filter -Z",
            "iptables -t filter -P FORWARD  DROP"
          ]
        end
        
        def init_ebtables
          [
              "ebtables -t nat --init-table",
              "ebtables -t filter --init-table",
              "ebtables -t filter -P FORWARD DROP"
          ]
        end
      end

      class ControllerFactory
        def self.create_controller(node)
          NetfilterController.new(node)
        end
      end
      
    end

    module Bandwidth
      include Dcmgr::Helpers::NicHelper
      include Dcmgr::Logger

      def clear_bandwidth_limits
        logger.debug "Removing all bandwidth limits"
        "tc qdisc del dev #{find_nic(@node.manifest.config.hv_ifindex)} root"
      end


      # Enforces the bandwidth limits set for the networks.
      # This uses the tc command to do so.
      # _networks_ is an array containing the networks to set
      # the bandwidth limits for.
      def limit_bandwidth(networks)
        bandwidth_cmd = []
        #raise ArgumentError unless inst_maps.is_a?(Hash)
        nic = find_nic(@node.manifest.config.hv_ifindex)

        #Determine the physical nic's peed in Mbit/s
        speed = %x{ethtool #{nic} | grep Speed | cut -d ' ' -f2}.chomp.to_i

        #Set up root disc
        bandwidth_cmd << "tc qdisc add dev #{nic} root handle 1: htb"
        bandwidth_cmd << "tc class add dev #{nic} parent 1: classid 1:1 htb rate #{speed}mbit ceil #{speed}mbit"

        networks.each { |nw|
          next if nw[:bandwidth].nil?

          logger.debug "Limiting bandwidth to #{nw[:bandwidth]}Mbit/s for #{nw[:uuid]}."

          #Set up the bandwidth limit for this network
          bandwidth_cmd << "tc class add dev #{nic} parent 1:1 classid 1:1#{nw[:bandwidth_mark]} htb rate #{nw[:bandwidth]}mbit ceil #{nw[:bandwidth]}mbit prio 1"
          bandwidth_cmd << "tc qdisc add dev #{nic} parent 1:1#{nw[:bandwidth_mark]} handle 1#{nw[:bandwidth_mark]}: sfq perturb 10"
          bandwidth_cmd << "tc filter add dev #{nic} protocol ip parent 1: prio 1 handle #{nw[:bandwidth_mark]} fw classid 1:1#{nw[:bandwidth_mark]}"

          #Mark the packets passing through this network
          ["s","d"].each { |x| bandwidth_cmd << "iptables -A FORWARD -#{x} #{nw[:ipv4_network]}/#{nw[:prefix]} -j MARK --set-mark 0x#{nw[:bandwidth_mark]}" }
        }

        bandwidth_cmd
      end
    end

    module Nat
      include Dcmgr::Helpers::NicHelper
      include Dcmgr::Logger
      
      # Quick and dirty hack to unlink the nat chains before deleting them.
      # It would be cleaner to recall the creation method with a :delete action
      # but NAT rules are based on IP leases and those are deleted on instance termination
      # Therefore we use grep to get the referring rules based on vnic uuid and then delete them.
      # Run build_nat_chains(inst_map, :delete) afterwards to delete the chains themselves
      def unlink_nat_chains(inst_map)
        raise ArgumentError, "inst_map must be a Hash." unless inst_map.is_a?(Hash)

        del_cmds = []
        inst_map[:instance_nics].each { |nic|
          post = %x{iptables -t nat -L POSTROUTING --line-numbers | grep s_#{nic[:uuid]} | tr -s ' ' | cut -d ' ' -f1}.chomp
          pre = %x{iptables -t nat -L PREROUTING --line-numbers | grep d_#{nic[:uuid]} | tr -s ' ' | cut -d ' ' -f1}.chomp

          del_cmds << "iptables -t nat -D POSTROUTING #{post}" unless post.empty?
          del_cmds << "iptables -t nat -D PREROUTING #{pre}" unless pre.empty?
        }

        del_cmds
      end
      
      # Similar hack to unlink_nat_chains. Once an instance is terminated,
      # we no longer know which IP it had so we grep the rules by mac address
      # and delete them by rule numer
      def stop_arp_reply(inst_map)
        raise ArgumentError, "inst_map must be a Hash." unless inst_map.is_a?(Hash)

        del_cmds = []

        inst_map[:instance_nics].each { |nic|
          mac = clean_mac(nic[:mac_addr])
          rule_number = %x{ebtables -t nat -L --Ln --Lmac2 | grep #{mac} | cut -d '.' -f1}
          del_cmds << "ebtables -t nat -D PREROUTING #{rule_number}" unless rule_number.empty?
        }

        del_cmds
      end
      
      # Builds or deletes the chains for each vnic in an instance.
      # We use different chains for incoming and outgoing packets per vnic
      # This way every packet only needs to be checked against chains that
      # are specifically intended for it.
      # _inst_map_ is a map of the instance to build or delte chains for.
      # _action_ decides wether we will create or delete the rules. It can be
      # either of the following:
      # * :create is the default value and creates chains for _inst_map_
      # * :delete deletes the chains for _inst_map_
      def build_nat_chains(inst_map, action = :create)
        actions = { :create => ['N'], :delete => ['F', 'X'] }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}." unless actions.keys.member?(action)
        raise ArgumentError, "inst_map must be a Hash." unless inst_map.is_a?(Hash)

        chain_cmds = []
        inst_map[:instance_nics].each { |nic|
          ['s','d'].each { |bound|
            actions[action].each { |a|
              chain_cmds << "iptables -t nat -#{a} #{bound}_#{nic[:uuid]}"
            }
          }
        }

        chain_cmds
      end

      # Takes an instance and nats it.
      # If the instance is in a network that has a nat_network mapped to it,
      # it will receive a second ip lease for that network. This lease will then be
      # natted to the ip the instance already had in its own network.
      # For example if 192.168.0.0/24 is natted to 172.16.0.0/16, then
      # an instance with ip 192.168.0.10 might be natted to ip 172.16.46.23.
      def nat_instance(inst_map)
        raise ArgumentError, "inst_map must be a Hash." unless inst_map.is_a?(Hash)

        nat_cmd = []

        inst_map[:instance_nics].each { |nic|
          # strict check
          next unless valid_nic?(nic[:uuid])

          nat_ips = rpc.request('hva-collector', 'get_nat_leases', nic[:uuid]).map {|ip| IPAddress(ip)}

          #Get the internal ip for this nic
          internal_ip = IPAddress rpc.request('hva-collector', 'get_iplease_for_nic', nic[:uuid])
          inside_exception_ips = rpc.request('hva-collector','get_group_instance_ipv4s',inst_map[:uuid]).map {|ip| IPAddress(ip)}
          outside_exception_ips = rpc.request('hva-collector','get_group_instance_ipv4s',inst_map[:uuid],:outside).map {|ip| IPAddress(ip)}

          #output the commands to nat this nic and answer arp requests for its outside ip
          friend_ipset  = nic[:uuid] + "_friend_ips"
          nat_ips.each { |external_ip|
            if @node.manifest.config.use_ipset

              nat_cmd << "ipset -N #{friend_ipset} iphash"

              inside_exception_ips.each { |ex_ip|
                nat_cmd << "ipset -A #{friend_ipset} #{ex_ip.address}"
              }

              # The good rules that use ipset              
              postrouting_command = "iptables -t nat -A s_#{nic[:uuid]} -s #{internal_ip.address} -m set ! --match-set #{friend_ipset} dst"
              prerouting_command = "iptables -t nat -A d_#{nic[:uuid]} -d #{external_ip.address} -m set ! --match-set #{friend_ipset} src"
            else
              # The ugly rules to use in case ipset is not installed
              postrouting_command = "iptables -t nat -A s_#{nic[:uuid]} -s #{internal_ip.address}"
              prerouting_command = "iptables -t nat -A d_#{nic[:uuid]} -d #{external_ip.address}"
            end

            # Set up the proper chain jumps
            nat_cmd << "iptables -t nat -A PREROUTING -d #{external_ip.address} -j d_#{nic[:uuid]}"
            nat_cmd << "iptables -t nat -A POSTROUTING -s #{internal_ip.address} -j s_#{nic[:uuid]}"

            # Build the final nat rules and log any packets that traverse them
            nat_cmd << postrouting_command  + " -j LOG --log-prefix 'Snat '" if @node.manifest.config.packet_drop_log
            nat_cmd << postrouting_command  + " -j SNAT --to #{external_ip.address}"

            nat_cmd << prerouting_command + " -j LOG --log-prefix 'Dnat '" if @node.manifest.config.packet_drop_log
            nat_cmd << prerouting_command + " -j DNAT --to #{internal_ip.address}"

            logger.debug "Natting #{internal_ip.address} to #{external_ip.address}"

            mac = clean_mac(nic[:mac_addr])
            nat_cmd << arp_respond(external_ip,mac)
          }
        }

        nat_cmd
      end

      # Returns the netfilter rules for destination IP addresses that
      # will not use static nat. These are the IP addresses of other instances
      # in the same security group.
      # _inst_map_ is a map of the instance that the rules will be defined for.
      def nat_exceptions(inst_map)
        inside_exception_ips = rpc.request('hva-collector','get_group_instance_ipv4s',inst_map[:uuid]).map {|ip| IPAddress(ip)}
        outside_exception_ips = rpc.request('hva-collector','get_group_instance_ipv4s',inst_map[:uuid],:outside).map {|ip| IPAddress(ip)}

        cmds = []
        inst_map[:instance_nics].each { |nic|
          # strict check
          next unless valid_nic?(nic[:uuid])

          internal_ip = IPAddress(rpc.request('hva-collector', 'get_iplease_for_nic', nic[:uuid]))
          inside_exception_ips.each { |ex_ip|
            cmds << "iptables -t nat -A s_#{nic[:uuid]} -s #{internal_ip.address} -d #{ex_ip.address}/#{ex_ip.prefix} -j ACCEPT"
          }
          outside_exception_ips.each { |ex_ip|
            cmds << "iptables -t nat -A d_#{nic[:uuid]} -s #{internal_ip.address} -d #{ex_ip.address}/#{ex_ip.prefix} -j ACCEPT"
          }
        }

        cmds
      end

      # Returns ebtables command to respond to ARP requests for the address _ip_.
      # _mac_addr_ is the mac address that we will reply with.
      def arp_respond(ip,mac_addr)
        ip = IPAddress(ip) if ip.is_a?(String)
        raise "Invalid IP address: #{ip}" unless ip.is_a?(IPAddress)

        #Get the mac address for our physical nic
        #nic = find_nic(@node.manifest.config.hv_ifindex)
        #TODO: Find a prettier way to get the mac address
        #mac_addr = %x{ifconfig | grep '#{nic}' | tr -s ' ' | cut -d ' ' -f5}.chomp

        logger.debug "Replying ARP requests for address: #{ip.address}"

        "ebtables -t nat -A PREROUTING -p arp --arp-ip-dst #{ip.address} --arp-opcode REQUEST -j arpreply --arpreply-mac #{mac_addr}"
      end

      def is_natted_ip?(ip)
        ip = IPAddress(ip) if ip.is_a?(String)
        raise ArgumentError, "Invalid IP address: #{ip}" unless ip.is_a?(IPAddress)

        rpc.request('hva-collector', 'is_natted_ip?', ip.address)
      end
    end

    class ServiceNetfilter < Isono::NodeModules::Base
      include Dcmgr::Logger
      include Dcmgr::Helpers::NicHelper
      include Nat
      include Bandwidth
      
      attr_accessor :controller

      initialize_hook do
        @worker_thread = Isono::ThreadPool.new(1, 'Netfilter')

        @worker_thread.pass {
          myinstance.init_netfilter
          #sleep 1
          # Initializing the controller will also apply netfilter rules for every alive instance
          #myinstance.controller = NewDesign::ControllerFactory.create_controller(myinstance.node)
        }

        event = Isono::NodeModules::EventChannel.new(node)

        event.subscribe('hva/instance_started', '#') do |args|
          @worker_thread.pass {
            logger.info("refresh on instance_started: #{args.inspect}")
            inst_id = args[0]
            logger.info("add_netfilter_by_instance_id: #{inst_id}")
            myinstance.add_netfilter_by_instance_id(inst_id)
            #myinstance.controller.apply_instance(inst_id)
          }
        end

        event.subscribe('hva/instance_terminated', '#') do |args|
          @worker_thread.pass {
            logger.info("refresh on instance_terminated: #{args.inspect}")
            inst_id = args[0]
            logger.info("delete_netfilter_by_instance_id: #{inst_id}")
            myinstance.delete_netfilter_by_instance_id(inst_id)
            #myinstance.controller.remove_instance(inst_id)
          }
        end

        event.subscribe('hva/security_group_updated', '#') do |args|
          @worker_thread.pass {
            logger.info("refresh on netfilter_updated: #{args.inspect}")
            security_group_id = args[0]
            myinstance.refresh_netfilter_by_joined_security_group_id(security_group_id)
            #myinstance.controller.update_security_group(security_group_id)
          }
        end
      end

      def init_netfilter
        begin
          inst_maps = rpc.request('hva-collector', 'get_alive_instances', node.node_id)

          viftable_map = {}
          inst_maps = inst_maps.map { |inst_map|
            viftable_map[ inst_map[:ips].first ] = inst_map[:instance_nics].first[:uuid]

            # Does the hva have instance?
            unless inst_map[:host_node][:node_id] == node.node_id
              logger.warn("no match for the instance: #{inst_map[:uuid]}")
              next
            end
            # Does host have vif?
            next unless valid_nic?(inst_map[:instance_nics].first[:uuid])
            inst_maps
          }.flatten.uniq.compact

          init_iptables(inst_maps) if @node.manifest.config.enable_iptables
          init_ebtables(inst_maps, viftable_map) if @node.manifest.config.enable_ebtables
          init_static_nat(inst_maps) if @node.manifest.config.enable_iptables && @node.manifest.config.enable_ebtables
          init_bandwidth_limit(networks = rpc.request('hva-collector', 'get_networks')) if @node.manifest.config.enable_iptables
          sleep 1

          logger.info("initialized netfilter")
        rescue Exception => e
          p e
        end
      end

      # This method created all netfilter rules for one instance.
      # It is called when starting a new instances
      # _inst_id_ is the canonical uuid of the instance whose netfilter rule are to be created.
      def add_netfilter_by_instance_id(inst_id)
        raise ArgumentError, "Unknown Instance ID: #{inst_id}" if inst_id.nil?
        inst_map = rpc.request('hva-collector', 'get_instance', inst_id)
        raise ArgumentError, "Unknown Instance ID: #{inst_id}" if inst_map.nil?

        cmds = []
        vif_map = build_vif_map(inst_map)
        viftable_map = {}
        viftable_map[ inst_map[:ips].first ] = inst_map[:instance_nics].first[:uuid]

        if @node.manifest.config.enable_ebtables
          cmds << build_ebtables_chains(vif_map,:create)
          cmds << build_ebtables_basic_part(vif_map, inst_map, :create)
          cmds << build_ebtables_group_part(vif_map, inst_map, viftable_map, :create)
          cmds << build_ebtables_final_part(vif_map, :create)
        end

        if @node.manifest.config.enable_iptables
          cmds << build_iptables_chains(protocol_map(:iptables), vif_map, :create)
          cmds << build_iptables_basic_part(vif_map, inst_map, :create)
          cmds << build_iptables_group_part(vif_map, inst_map, :create)
          cmds << build_iptables_final_part(vif_map, :create)
        end

        if @node.manifest.config.enable_ebtables && @node.manifest.config.enable_iptables
          cmds << build_nat_chains(inst_map)
          cmds << nat_exceptions(inst_map) unless @node.manifest.config.use_ipset
          cmds << nat_instance(inst_map)
        end
        
        do_exec(cmds)
      end

      # This method deletes all netfilter rules for one instance.
      # It is called when terminating an instance.
      # _inst_id_ The canonical uuid of the instance whose netfilter rules are to be deleted.
      def delete_netfilter_by_instance_id(inst_id)
        raise ArgumentError, "Unknown Instance ID: #{inst_id}" if inst_id.nil?
        inst_map = rpc.request('hva-collector', 'get_instance', inst_id)
        raise ArgumentError, "Unknown Instance ID: #{inst_id}" if inst_map.nil?

        #Create vnic map
        vif_map = build_vif_map(inst_map)

        #Delete ebtables chains
        cmds = []

        #Calling build_ebtables_basic_part with the :delete flag will delete all jumps to this instance's chains and then delete the chains themselves
        cmds << build_ebtables_basic_part(vif_map, inst_map, :delete) if @node.manifest.config.enable_ebtables

        #Delete nat chains
        if @node.manifest.config.enable_ebtables && @node.manifest.config.enable_iptables
          cmds << unlink_nat_chains(inst_map)
          cmds << stop_arp_reply(inst_map)
          cmds << build_nat_chains(inst_map, :delete)
        end

        #Delete iptables chains
        cmds << build_iptables_basic_part(vif_map, inst_map, :delete) if @node.manifest.config.enable_iptables

        do_exec(cmds)
      end

      # from event_subscriber
      def refresh_netfilter_by_friend_instance_id(inst_id)
        raise "UnknownInstanceID" if inst_id.nil?

        begin
          ng_maps = rpc.request('hva-collector', 'get_security_groups_of_instance', inst_id)
          # get friend instance(s)
          friend_inst_maps = ng_maps.map { |ng_map|
            rpc.request('hva-collector', 'get_instances_of_security_group', ng_map[:id])
          }.flatten.uniq
          guest_inst_maps = rpc.request('hva-collector', 'get_alive_instances', node.node_id)

          uuids = friend_inst_maps.map { |inst_map| inst_map[:uuid] } & guest_inst_maps.map  { |inst_map| inst_map[:uuid] }
          logger.info("my guest instance(s)?: #{uuids.inspect}")

          if uuids.flatten.uniq.size > 0
            init_netfilter
          else
            # group_instance: 1->0
            inst_map = rpc.request('hva-collector', 'get_instance', inst_id)
            init_netfilter if inst_map[:host_node][:node_id] == node.node_id
          end
        rescue Exception => e
          p e
        end
      end

      # from event_subscriber
      def refresh_netfilter_by_joined_security_group_id(security_group_id)
        raise "Unknown security group ID: #{security_group_id}" if security_group_id.nil?

        begin
          inst_maps = rpc.request('hva-collector', 'get_instances_of_security_group', security_group_id)
          init_netfilter if inst_maps.size > 0
        rescue Exception => e
          p e
        end
      end

      def build_vif_map(inst_map = {})
        vif_map = {
          :uuid  => inst_map[:instance_nics].first[:uuid],
          :mac   => clean_mac(inst_map[:instance_nics].first[:mac_addr]),
          :ipv4  => inst_map[:ips].first,
        }
      end

      def protocol_map(type)
        case type
        when :iptables
          {
            'tcp'  => 'tcp',
            'udp'  => 'udp',
            'icmp' => 'icmp',
          }
        when :ebtables
          {
            'ip4'  => 'ip4',
            'arp'  => 'arp',
            #'ip6'  => 'ip6',
            #'rarp' => '0x8035',
          }
        end
      end

      def do_exec(cmds)
        recmds = []

        eos = "__EOS_#{Isono::Util.gen_id}___"
        recmds << "/bin/cat <<'#{eos}' | /bin/bash"
        cmds.flatten.uniq.each { |cmd|
          puts cmd if @node.manifest.config.verbose_netfilter == true
          recmds << cmd
        }
        recmds << "#{eos}"

        logger.debug("applying rule line(s): #{recmds.size - 2}")
        system(recmds.join("\n"))
        logger.debug("applied rule line(s): #{recmds.size - 2}")
      end

      def init_ebtables(inst_maps = [], viftable_map = {})
        init_cmds  = []
        basic_cmds = []
        group_cmds = []
        nat_cmds   = []
        final_cmds = []

        init_cmds << "ebtables --init-table"
        #Clear the nat table. This table is only used in build_ebtables_nat_part
        init_cmds << "ebtables -t nat --init-table"

        inst_maps.each { |inst_map|
          vif_map = build_vif_map(inst_map)

          basic_cmds << build_ebtables_basic_part(vif_map, inst_map)
          group_cmds << build_ebtables_group_part(vif_map, inst_map, viftable_map)
          final_cmds << build_ebtables_final_part(vif_map)
        }

        viftable_map.each { |k,v|
          logger.debug("viftable: #{v} <=> #{k}")
        }

        do_exec([init_cmds, basic_cmds, group_cmds, final_cmds])
      end

      def init_iptables(inst_maps = [])
        init_cmds  = []
        basic_cmds = []
        group_cmds = []
        nat_cmds   = []
        final_cmds = []

        #Drop all packets that aren't explicitely allowed
        #init_cmds << "iptables -P FORWARD DROP"
        init_cmds << "iptables -P FORWARD ACCEPT"

        [ 'raw', 'nat', 'filter' ].each { |table|
          [ 'F', 'Z', 'X' ].each { |xcmd|
            init_cmds << "iptables -t #{table} -#{xcmd}"
          }
        }

        if @node.manifest.config.use_ipset
          ['F','X'].each { |xcmd|
            init_cmds << "ipset -#{xcmd}"
          }
        end

        # via http://backreference.org/2010/06/11/iptables-debugging/
        # To debug ipv4 packets.
        # $ sudo tail -F /var/log/kern.log | grep TRACE:
        if @node.manifest.config.debug_iptables
          init_cmds << "iptables -t raw -A OUTPUT -p icmp -j TRACE"
          init_cmds << "iptables -t raw -A PREROUTING -p icmp -j TRACE"
        end

        inst_maps.each { |inst_map|
          vif_map = build_vif_map(inst_map)

          basic_cmds << build_iptables_basic_part(vif_map, inst_map)
          group_cmds << build_iptables_group_part(vif_map, inst_map)
          final_cmds << build_iptables_final_part(vif_map)
        }

        do_exec([init_cmds, basic_cmds, group_cmds, final_cmds])
      end

      def init_static_nat(inst_maps = [])
        chain_cmds  = []
        #ref_cmds    = []
        accept_cmds = []
        nat_cmds    = []

        inst_maps.each { |inst_map|
          chain_cmds  << build_nat_chains(inst_map)
          #ref_cmds    = ref_nat_chains(inst_map)
          accept_cmds << nat_exceptions(inst_map) unless @node.manifest.config.use_ipset
          nat_cmds    << nat_instance(inst_map)
        }

        do_exec([chain_cmds,accept_cmds,nat_cmds])
      end

      def init_bandwidth_limit(network_maps)
        do_exec([clear_bandwidth_limits,limit_bandwidth(network_maps)])
      end

      def build_ebtables_chains(vif_map,action = :create)
        actions = { :create => 'N' , :delete => 'X' }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}" unless actions.keys.member?(action)
        ################################
        ## 0. chain name
        ################################

        # support IP protocol
        protocol_map = protocol_map(:ebtables)

        # make chain names.
        chains = []
        chains << "s_#{vif_map[:uuid]}"
        chains << "d_#{vif_map[:uuid]}"
        chains << "s_#{vif_map[:uuid]}_d_hst"
        chains << "d_#{vif_map[:uuid]}_s_hst"
        protocol_map.each { |k,v|
          chains << "s_#{vif_map[:uuid]}_#{k}"
          chains << "d_#{vif_map[:uuid]}_#{k}"
          chains << "s_#{vif_map[:uuid]}_d_hst_#{k}"
          chains << "d_#{vif_map[:uuid]}_s_hst_#{k}"
        }

        # create user defined chains.
        cmds = chains.map { |chain|
          "ebtables -#{actions[action]} #{chain}"
        }

        cmds
      end

      def build_ebtables_basic_part(vif_map, inst_map, action = :create)
        basic_cmds = []

        actions = { :create => 'A' , :delete => 'D' }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}" unless actions.keys.member?(action)

        hva_ipv4 = Isono::Util.default_gw_ipaddr

        ################################
        ## 1. basic part
        ################################
        
        protocol_map = protocol_map(:ebtables)

        basic_cmds << build_ebtables_chains(vif_map,action) if action == :create

        # jumt to user defined chains
        basic_cmds << "ebtables -#{actions[action]} FORWARD -i #{vif_map[:uuid]} -j s_#{vif_map[:uuid]}"
        basic_cmds << "ebtables -#{actions[action]} FORWARD -o #{vif_map[:uuid]} -j d_#{vif_map[:uuid]}"
        basic_cmds << "ebtables -#{actions[action]} INPUT   -i #{vif_map[:uuid]} -j s_#{vif_map[:uuid]}_d_hst"
        basic_cmds << "ebtables -#{actions[action]} OUTPUT  -o #{vif_map[:uuid]} -j d_#{vif_map[:uuid]}_s_hst"

        # IP protocol routing
        protocol_map.each { |k,v|
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}       -p #{v} -j s_#{vif_map[:uuid]}_#{k}"
          basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}       -p #{v} -j d_#{vif_map[:uuid]}_#{k}"
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst -p #{v} -j s_#{vif_map[:uuid]}_d_hst_#{k}"
          basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_s_hst -p #{v} -j d_#{vif_map[:uuid]}_s_hst_#{k}"
        }

        if @node.manifest.config.packet_drop_log
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}       --log-level 4 --log-ip --log-arp --log-prefix 'D s_#{vif_map[:uuid]}:'       -j CONTINUE" if @node.manifest.config.packet_drop_log
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst --log-level 4 --log-ip --log-arp --log-prefix 'D s_#{vif_map[:uuid]}_d_hst:' -j CONTINUE" if @node.manifest.config.packet_drop_log
        end
        basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}       -j DROP"
        basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst -j DROP"
        # anti spoof: mac    # guest -> *
        basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_arp       --protocol arp --arp-mac-src ! #{vif_map[:mac]} --log-ip --log-arp --log-prefix 'Dmc s_#{vif_map[:uuid]}_arp:'       -j CONTINUE" if @node.manifest.config.packet_drop_log
        basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-mac-src ! #{vif_map[:mac]} --log-ip --log-arp --log-prefix 'Dmc s_#{vif_map[:uuid]}_d_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
        basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_arp       --protocol arp --arp-mac-src ! #{vif_map[:mac]} -j DROP"
        basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-mac-src ! #{vif_map[:mac]} -j DROP"
        # guest <- * (broadcast)
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp                          --arp-mac-dst 00:00:00:00:00:00 --log-ip --log-arp --log-prefix 'Amc d_#{vif_map[:uuid]}_arp:'     -j CONTINUE" if @node.manifest.config.packet_drop_log
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_s_hst_arp --protocol arp --arp-ip-src=#{hva_ipv4} --arp-mac-dst 00:00:00:00:00:00 --log-ip --log-arp --log-prefix 'Amc d_#{vif_map[:uuid]}_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp                          --arp-mac-dst 00:00:00:00:00:00 -j ACCEPT"
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_s_hst_arp --protocol arp --arp-ip-src=#{hva_ipv4} --arp-mac-dst 00:00:00:00:00:00 -j ACCEPT"

        # guest <- *
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp --arp-mac-dst ! #{vif_map[:mac]} --log-ip --log-arp --log-prefix 'Dmc d_#{vif_map[:uuid]}_arp:'       -j CONTINUE" if @node.manifest.config.packet_drop_log
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_s_hst_arp --protocol arp --arp-mac-dst ! #{vif_map[:mac]} --log-ip --log-arp --log-prefix 'Dmc d_#{vif_map[:uuid]}_s_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp --arp-mac-dst ! #{vif_map[:mac]} -j DROP"
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_s_hst_arp --protocol arp --arp-mac-dst ! #{vif_map[:mac]} -j DROP"

        # anti spoof: ipv4
        inst_map[:ips].each { |ipv4|
          # guest -> *
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_arp       --protocol arp --arp-ip-src ! #{ipv4} --log-ip --log-arp --log-prefix 'Dip s_#{vif_map[:uuid]}_arp:'       -j CONTINUE" if @node.manifest.config.packet_drop_log
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-ip-src ! #{ipv4} --log-ip --log-arp --log-prefix 'Dip s_#{vif_map[:uuid]}_d_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_arp       --protocol arp --arp-ip-src ! #{ipv4} -j DROP"
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-ip-src ! #{ipv4} -j DROP"
          # guest <- *
          basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp --arp-ip-dst ! #{ipv4} --log-ip --log-arp --log-prefix 'Dip d_#{vif_map[:uuid]}_arp:'       -j CONTINUE" if @node.manifest.config.packet_drop_log
          basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_s_hst_arp --protocol arp --arp-ip-dst ! #{ipv4} --log-ip --log-arp --log-prefix 'Dip d_#{vif_map[:uuid]}_s_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
          basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp --arp-ip-dst ! #{ipv4} -j DROP"
          basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_s_hst_arp --protocol arp --arp-ip-dst ! #{ipv4} -j DROP"
        }

        basic_cmds << build_ebtables_chains(vif_map,action) if action == :delete
        basic_cmds
      end

      def build_ebtables_group_part(vif_map, inst_map, viftable_map, action = :create)
        group_cmds = []
        hva_ipv4 = Isono::Util.default_gw_ipaddr
        actions = { :create => 'A' , :delete => 'D' }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}" unless actions.keys.member?(action)

        ################################
        ## 2. group part
        ################################
        same_subnet_ipv4s = rpc.request('hva-collector', 'get_group_instance_ipv4s', inst_map[:uuid])

        network_map = rpc.request('hva-collector', 'get_network', inst_map[:instance_nics].first[:network_id])
        raise "UnknownNetworkId" if network_map.nil?
        joined_network = IPAddress("#{network_map[:ipv4_network]}/#{network_map[:prefix]}")

        [ network_map[:dns_server], network_map[:dhcp_server], network_map[:metadata_server] ].each { |ipv4|
          next if ipv4.nil? or not joined_network.include? IPAddress(ipv4)
          same_subnet_ipv4s << ipv4
        }

        # network resource node(s)
        ng_maps = rpc.request('hva-collector', 'get_security_groups_of_instance', inst_map[:uuid])
        rules = ng_maps.map { |ng_map|
          ng_map[:rules].map { |rule| rule[:permission] }
        }.flatten
        build_rule(rules).each do |rule|
          # <ArgumentError: Invalid IP "0.0.0.0">
          next if rule[:ip_source] == "0.0.0.0/0"

          begin
            next unless joined_network.include? IPAddress(rule[:ip_source])
            same_subnet_ipv4s << rule[:ip_source]
          rescue Exception => e
            #raise unless e.is_a? ArgumentError
            p e
          end
        end
        same_subnet_ipv4s << network_map[:ipv4_gw]

        # guest node(s) in HyperVisor.
        alive_inst_maps = rpc.request('hva-collector', 'get_alive_instances', node.node_id)
        guest_ipv4s = alive_inst_maps.map { |alive_inst_map|
          alive_inst_map[:ips]
        }.flatten.uniq.compact

        same_subnet_ipv4s.uniq.reverse_each do |ipv4|
          next if vif_map[:ipv4] == ipv4

          # get_macaddr_by_ipv4, ipv4
          if ipv4 == hva_ipv4
            #p "#{vif_map[:uuid]}(#{vif_map[:ipv4]}) -> [host] ***-****** (#{ipv4})"
            group_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-ip-src #{vif_map[:ipv4]} --arp-ip-dst #{ipv4} --log-ip --log-arp --log-prefix 'Afw s_#{vif_map[:uuid]}_d_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
            group_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-ip-src #{vif_map[:ipv4]} --arp-ip-dst #{ipv4} -j ACCEPT"
          elsif guest_ipv4s.include?(ipv4)
            #p "#{vif_map[:uuid]}(#{vif_map[:ipv4]}) -> [guest] #{viftable_map[ipv4]}(#{ipv4})"

            # guest->guest
            group_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp --arp-ip-src #{ipv4} --arp-ip-dst #{vif_map[:ipv4]} --log-ip --log-arp --log-prefix 'Afw d_#{vif_map[:uuid]}_arp:'       -j CONTINUE" if @node.manifest.config.packet_drop_log
            group_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp --arp-ip-src #{ipv4} --arp-ip-dst #{vif_map[:ipv4]} -j ACCEPT"
            # guest->host
            group_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-ip-src #{vif_map[:ipv4]} --arp-ip-dst #{ipv4} --log-ip --log-arp --log-prefix 'Afw s_#{vif_map[:uuid]}_d_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
            group_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-ip-src #{vif_map[:ipv4]} --arp-ip-dst #{ipv4} -j ACCEPT"

            unless viftable_map[ipv4].nil?
              # guest->guest
              group_cmds << "ebtables -#{actions[action]} d_#{viftable_map[ipv4]}_arp       --protocol arp --arp-ip-src #{vif_map[:ipv4]} --arp-ip-dst #{ipv4} --log-ip --log-arp --log-prefix 'Arv d_#{viftable_map[ipv4]}_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
              group_cmds << "ebtables -#{actions[action]} d_#{viftable_map[ipv4]}_arp       --protocol arp --arp-ip-src #{vif_map[:ipv4]} --arp-ip-dst #{ipv4} -j ACCEPT"

              # guest->host
              group_cmds << "ebtables -#{actions[action]} s_#{viftable_map[ipv4]}_d_hst_arp --protocol arp --arp-ip-src #{ipv4} --arp-ip-dst #{vif_map[:ipv4]} --log-ip --log-arp --log-prefix 'Arv s_#{viftable_map[ipv4]}_d_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
              group_cmds << "ebtables -#{actions[action]} s_#{viftable_map[ipv4]}_d_hst_arp --protocol arp --arp-ip-src #{ipv4} --arp-ip-dst #{vif_map[:ipv4]} -j ACCEPT"
            end
          else
            #p "#{vif_map[:uuid]}(#{vif_map[:ipv4]}) -> [other] ***-******** (#{ipv4})"
            group_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp --protocol arp --arp-ip-src #{ipv4} --arp-ip-dst #{vif_map[:ipv4]} --log-ip --log-arp --log-prefix 'Afw :d_#{vif_map[:uuid]}_arp' -j CONTINUE" if @node.manifest.config.packet_drop_log
            group_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp --protocol arp --arp-ip-src #{ipv4} --arp-ip-dst #{vif_map[:ipv4]} -j ACCEPT"
          end
        end

        group_cmds
      end

      def build_ebtables_final_part(vif_map, action = :create)
        final_cmds = []
        actions = { :create => 'A' , :delete => 'D' }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}" unless actions.keys.member?(action)

        ################################
        ## 3. final part
        ################################
        # deny,allow
        final_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --log-level 4 --log-ip --log-arp --log-prefix 'D d_#{vif_map[:uuid]}_arp:'       -j CONTINUE" if @node.manifest.config.packet_drop_log
        final_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --log-level 4 --log-ip --log-arp --log-prefix 'D s_#{vif_map[:uuid]}_d_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
        final_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       -j DROP"
        final_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp -j DROP"

        final_cmds
      end

      def build_iptables_chains(protocol_map, vif_map, action = :create)
        actions = { :create => ['N'] , :delete => ['F','X'] }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}" unless actions.keys.member?(action)

        chain_cmds = []

        ################################
        ## 0. chain name
        ################################

        [ 's', 'd' ].each do |bound|
          protocol_map.each { |k,v|
            actions[action].each do |act|
              chain_cmds << "iptables -#{act} #{bound}_#{vif_map[:uuid]}"
              chain_cmds << "iptables -#{act} #{bound}_#{vif_map[:uuid]}_#{k}"

              chain_cmds << "iptables -#{act} #{bound}_#{vif_map[:uuid]}_drop"
              chain_cmds << "iptables -#{act} #{bound}_#{vif_map[:uuid]}_#{k}_drop"
            end
          }
        end

        chain_cmds
      end

      def build_iptables_basic_part(vif_map, inst_map, action = :create)
        basic_cmds = []

        actions = { :create => 'A' , :delete => 'D' }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}" unless actions.keys.member?(action)

        network_map = rpc.request('hva-collector', 'get_network', inst_map[:instance_nics].first[:network_id])
        raise "UnknownNetworkId" if network_map.nil?

        # support IP protocol
        protocol_map = protocol_map(:iptables)

        # make chain names.
        basic_cmds << build_iptables_chains(protocol_map, vif_map, :create) if action == :create

        ################################
        ## 1. basic part
        ################################

        # metadata-server (parameter can be nil)
        if  network_map[:metadata_server]
          port = network_map[:metadata_server_port] || 80
          basic_cmds << "iptables -t nat -#{actions[action]} PREROUTING -m physdev --physdev-in #{vif_map[:uuid]} -d 169.254.169.254 -p tcp --dport 80 -j DNAT --to-destination #{network_map[:metadata_server]}:#{port}"
        end
        # DHCP Server (parameter can be nil)
        if network_map[:dhcp_server]
          # Reject any DHCP packets from other than dhcp_server in the network table.
          basic_cmds << "iptables -#{actions[action]} d_#{vif_map[:uuid]} -p udp ! -s #{network_map[:dhcp_server]} --sport 67 -j d_#{vif_map[:uuid]}_udp_drop"
          basic_cmds << "iptables -#{actions[action]} d_#{vif_map[:uuid]} -p udp ! -s #{network_map[:dhcp_server]} --sport 68 -j d_#{vif_map[:uuid]}_udp_drop"
        end

        # group nodes
        # group node IPv4 addresses.
        ipv4s = rpc.request('hva-collector', 'get_group_instance_ipv4s', inst_map[:uuid])
        ipv4s << network_map[:ipv4_gw]
        ipv4s.uniq.reverse_each { |addr|
          basic_cmds << "iptables -#{actions[action]} d_#{vif_map[:uuid]} -s #{addr} -j ACCEPT"
        }

        # IP protocol routing
        [ 's', 'd' ].each do |bound|
          protocol_map.each { |k,v|
            #basic_cmds << "iptables -#{chain_actions[action]} #{bound}_#{vif_map[:uuid]}_#{k}"
            # Log dropped packets
            ["#{bound}_#{vif_map[:uuid]}", "#{bound}_#{vif_map[:uuid]}_#{k}"].each { |chain|
              basic_cmds << "iptables -#{actions[action]} #{chain}_drop -j LOG --log-level 4 --log-prefix 'D #{chain}:'" if @node.manifest.config.packet_drop_log
              basic_cmds << "iptables -#{actions[action]} #{chain}_drop -j DROP"
            }

            case k
            when 'tcp'
              case bound
              when 's'
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -m state --state NEW,ESTABLISHED -p #{k} -j #{bound}_#{vif_map[:uuid]}_#{k}"
              when 'd'
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -m state --state RELATED,ESTABLISHED -p #{k} -j ACCEPT"
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -p #{k} -j #{bound}_#{vif_map[:uuid]}_#{k}"
              end
            when 'udp'
              case bound
              when 's'
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -m state --state NEW,ESTABLISHED -p #{k} -j #{bound}_#{vif_map[:uuid]}_#{k}"
              when 'd'
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -m state --state ESTABLISHED -p #{k} -j ACCEPT"
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -p #{k} -j #{bound}_#{vif_map[:uuid]}_#{k}"
              end
            when 'icmp'
              case bound
              when 's'
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -m state --state NEW,ESTABLISHED,RELATED -p #{k} -j #{bound}_#{vif_map[:uuid]}_#{k}"
              when 'd'
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -m state --state ESTABLISHED,RELATED -p #{k} -j ACCEPT"
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -p #{k} -j #{bound}_#{vif_map[:uuid]}_#{k}"
              end
            end
          }
        end

        # Dispatch packets to s_ or d_ chain.
        # s_: for out-bound, go out from VM.
        # d_: for in-bound, go into VM.
        basic_cmds << "iptables -#{actions[action]} FORWARD -m physdev --physdev-is-bridged --physdev-in  #{vif_map[:uuid]} -j s_#{vif_map[:uuid]}"
        basic_cmds << "iptables -#{actions[action]} FORWARD -m physdev --physdev-is-bridged --physdev-out #{vif_map[:uuid]} -j d_#{vif_map[:uuid]}"

        ##
        ## ACCEPT
        ##
        # DHCP Server (parameter can be nil)
        if network_map[:dhcp_server]
          basic_cmds << "iptables -#{actions[action]} d_#{vif_map[:uuid]}_udp -p udp -s #{network_map[:dhcp_server]} --sport 67 -j ACCEPT"
          basic_cmds << "iptables -#{actions[action]} d_#{vif_map[:uuid]}_udp -p udp -s #{network_map[:dhcp_server]} --sport 68 -j ACCEPT"
        end
        
        # DNS Server (parameter can be nil)
        if network_map[:dns_server]
          basic_cmds << "iptables -#{actions[action]} s_#{vif_map[:uuid]}_udp -p udp -d #{network_map[:dns_server]} --dport 53 -j ACCEPT"
        end
        # MetaData Server (parameter can be nil)
        if network_map[:metadata_server]
          basic_cmds << "iptables -#{actions[action]} s_#{vif_map[:uuid]}_tcp -p tcp -d #{network_map[:metadata_server]} --dport #{network_map[:metadata_server_port]} -j ACCEPT"
        end
        ##
        ## DROP
        ##
        protocol_map.each { |k,v|
          # DHCP
          if network_map[:dhcp_server]
            basic_cmds << "iptables -#{actions[action]} s_#{vif_map[:uuid]} -d #{network_map[:dhcp_server]} -p #{k} -j s_#{vif_map[:uuid]}_#{k}_drop"
          end
          # DNS
          if network_map[:dns_server]
            basic_cmds << "iptables -#{actions[action]} s_#{vif_map[:uuid]} -d #{network_map[:dns_server]} -p #{k} -j s_#{vif_map[:uuid]}_#{k}_drop"
          end
        }

        basic_cmds << build_iptables_chains(protocol_map, vif_map, :delete) if action == :delete

        basic_cmds
      end

      def build_iptables_group_part(vif_map, inst_map, action = :create)
        group_cmds = []

        ################################
        ## 2. group part
        ################################
        
        case action
          when :delete
            protocol_map(:iptables).each { |k,v|
              # Fluch all security group chains
              group_cmds << "iptables -A d_#{vif_map[:uuid]}_#{k} -F"
            }
          when :create
            ng_maps = rpc.request('hva-collector', 'get_security_groups_of_instance', inst_map[:uuid])
            rules = ng_maps.map { |ng_map|
              ng_map[:rules].map { |rule| rule[:permission] }
            }.flatten

            # security group
            build_rule(rules).each do |rule|
              case rule[:ip_protocol]
              when 'tcp', 'udp'
                if rule[:ip_fport] == rule[:ip_tport]
                  group_cmds << "iptables -A d_#{vif_map[:uuid]}_#{rule[:ip_protocol]} -p #{rule[:ip_protocol]} -s #{rule[:ip_source]} --dport #{rule[:ip_fport]} -j ACCEPT"
                else
                  group_cmds << "iptables -A d_#{vif_map[:uuid]}_#{rule[:ip_protocol]} -p #{rule[:ip_protocol]} -s #{rule[:ip_source]} --dport #{rule[:ip_fport]}:#{rule[:ip_tport]} -j ACCEPT"
                end
              when 'icmp'
                # icmp
                #   This extension can be used if `--protocol icmp' is specified. It provides the following option:
                #   [!] --icmp-type {type[/code]|typename}
                #     This allows specification of the ICMP type, which can be a numeric ICMP type, type/code pair, or one of the ICMP type names shown by the command
                #      iptables -p icmp -h
                if rule[:icmp_type] == -1 && rule[:icmp_code] == -1
                  group_cmds << "iptables -A d_#{vif_map[:uuid]}_#{rule[:ip_protocol]} -p #{rule[:ip_protocol]} -s #{rule[:ip_source]} -j ACCEPT"
                else
                  group_cmds << "iptables -A d_#{vif_map[:uuid]}_#{rule[:ip_protocol]} -p #{rule[:ip_protocol]} -s #{rule[:ip_source]} --icmp-type #{rule[:icmp_type]}/#{rule[:icmp_code]} -j ACCEPT"
                end
              end
            end
          else
            raise ArgumentError, "#{action} is not a valid action."
        end
        group_cmds
      end

      def build_iptables_final_part(vif_map, action = :create)
        actions = { :create => 'A' , :delete => 'D' }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}" unless actions.keys.member?(action)

        final_cmds = []

        # support IP protocol
        protocol_map = protocol_map(:iptables)

        ################################
        ## 3. final part
        ################################

        # Send dropped ip packets to their respective drop chains, based on their protocol
        [ 'd' ].each do |bound|
          protocol_map.each { |k,v|
            # Any packets that travel the protocol specific chains and don't get accepted are directed to drop chains
            # where logging can take place before the packets are dropped by the FORWARD chain policy
            final_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -p #{k} -j #{bound}_#{vif_map[:uuid]}_#{k}_drop"
          }
        end

        # Allow outgoing traffic from the instance
        [ 's' ].each do |bound|
          protocol_map.each { |k,v|
            final_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]}_#{k} -p #{k} -j ACCEPT"
          }
        end

        final_cmds
      end

      def build_rule(rules = [])
        rule_maps = []

        rules.each do |rule|
          rule = rule.strip.gsub(/[\s\t]+/, '')
          from_group = false
          ipv4s = []

          # ex.
          # "tcp:22,22,ip4:0.0.0.0"
          # "udp:53,53,ip4:0.0.0.0"
          # "icmp:-1,-1,ip4:0.0.0.0"

          # 1st phase
          # ip_tport    : tcp,udp? 1 - 16bit, icmp: -1
          # id_port has been separeted in first phase.
          from_pair, ip_tport, source_pair = rule.split(',')

          next if from_pair.nil?
          next if ip_tport.nil?
          next if source_pair.nil?

          # 2nd phase
          # ip_protocol : [ tcp | udp | icmp ]
          # ip_fport    : tcp,udp? 1 - 16bit, icmp: -1
          ip_protocol, ip_fport = from_pair.split(':')

          # protocol    : [ ip4 | ip6 | security_group_uuid ]
          # ip_source   : ip4? xxx.xxx.xxx.xxx./[0-32], ip6? (not yet supprted)
          protocol, ip_source = source_pair.split(':')

          begin
            s = StringScanner.new(protocol)
            until s.eos?
              case
              when s.scan(/ip6/)
                # TODO#FUTURE: support IPv6 address format
                next
              when s.scan(/ip4/)
                # IPAddress doesn't support prefix '0'.
                ip_addr, prefix = ip_source.split('/', 2)
                if prefix.to_i == 0
                  ip_source = ip_addr
                end
              when s.scan(/sg-\w+/)
                from_group = true
                inst_maps = rpc.request('hva-collector', 'get_instances_of_security_group', protocol)
                inst_maps.each { |inst_map|
                  ipv4s << inst_map[:ips]
                }
              else
                raise "unexpected protocol '#{s.peep(20)}'"
              end
            end
          rescue Exception => e
            p e
            next
          end

          begin
            if from_group == false
              #p "from_group:(#{from_group}) ip_source -> #{ip_source}"
              ip = IPAddress(ip_source)
              ip_source = case ip.u32
                          when 0
                            "#{ip.address}/0"
                          else
                            "#{ip.address}/#{ip.prefix}"
                          end
            else
              ipv4s = ipv4s.flatten.uniq
            end
          rescue Exception => e
            p e
            next
          end

          case ip_protocol
          when 'tcp', 'udp'
            ip_fport = ip_fport.to_i
            ip_tport = ip_tport.to_i

            # validate port range
            [ ip_fport, ip_tport ].each do |port|
              next unless port >= 1 && port <= 65535
            end

            if ip_fport <= ip_tport
              if from_group == false
                rule_maps << {
                  :ip_protocol => ip_protocol,
                  :ip_fport    => ip_fport,
                  :ip_tport    => ip_tport,
                  :protocol    => protocol,
                  :ip_source   => ip_source,
                }
              else
                ipv4s.each { |ip|
                  rule_maps << {
                    :ip_protocol => ip_protocol,
                    :ip_fport    => ip_fport,
                    :ip_tport    => ip_tport,
                    :protocol    => 'ip4',
                    :ip_source   => ip,
                  }
                }
              end
            end
          when 'icmp'
            # via http://docs.amazonwebservices.com/AWSEC2/latest/CommandLineReference/
            #
            # For the ICMP protocol, the ICMP type and code must be specified.
            # This must be specified in the format type:code where both are integers.
            # Type, code, or both can be specified as -1, which is a wildcard.

            icmp_type = ip_fport.to_i
            icmp_code = ip_tport.to_i

            # icmp_type
            case icmp_type
            when -1
            when 0, 3, 5, 8, 11, 12, 13, 14, 15, 16, 17, 18
            else
              next
            end

            # icmp_code
            case icmp_code
            when -1
            when 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
              # when icmp_type equals -1 icmp_code must equal -1.
              next if icmp_type == -1
            else
              next
            end

            if from_group == false
              rule_maps << {
                :ip_protocol => ip_protocol,
                :icmp_type   => ip_tport.to_i, # ip_tport.to_i, # -1 or 0,       3,    5,       8,        11, 12, 13, 14, 15, 16, 17, 18
                :icmp_code   => ip_fport.to_i, # ip_fport.to_i, # -1 or 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
                :protocol    => protocol,
                :ip_source   => ip_source,
              }
            else
              ipv4s.each { |ip|
                rule_maps << {
                  :ip_protocol => ip_protocol,
                  :icmp_type   => ip_tport.to_i, # ip_tport.to_i, # -1 or 0,       3,    5,       8,        11, 12, 13, 14, 15, 16, 17, 18
                  :icmp_code   => ip_fport.to_i, # ip_fport.to_i, # -1 or 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
                  :protocol    => 'ip4',
                  :ip_source   => ip,
                }
              }
            end
          end
        end

        rule_maps
      end

      def rpc
        @rpc ||= Isono::NodeModules::RpcChannel.new(@node)
      end

      def event
        @event ||= Isono::NodeModules::EventChannel.new(@node)
      end

    end
  end
end
