# -*- coding: utf-8 -*-
require 'isono'
require 'ipaddress'

module Dcmgr
  module NodeModules

    module Bandwidth
      include Dcmgr::Helpers::NicHelper
      include Dcmgr::Logger

      def clear_bandwidth_limits
        logger.debug "Removing all bandwidth limits"
        "tc qdisc del dev #{find_nic(@node.manifest.config.hv_ifindex)} root"
      end


      # Enforces the bandwidth limits set for the networks.
      # This uses the tc command to do so.
      # _networks_ is an array containing the networks to set
      # the bandwidth limits for.
      def limit_bandwidth(networks)
        bandwidth_cmd = []
        #raise ArgumentError unless inst_maps.is_a?(Hash)
        nic = find_nic(@node.manifest.config.hv_ifindex)

        #Determine the physical nic's peed in Mbit/s
        speed = %x{ethtool #{nic} | grep Speed | cut -d ' ' -f2}.chomp.to_i

        #Set up root disc
        bandwidth_cmd << "tc qdisc add dev #{nic} root handle 1: htb"
        bandwidth_cmd << "tc class add dev #{nic} parent 1: classid 1:1 htb rate #{speed}mbit ceil #{speed}mbit"

        networks.each { |nw|
          next if nw[:bandwidth].nil?

          logger.debug "Limiting bandwidth to #{nw[:bandwidth]}Mbit/s for #{nw[:uuid]}."

          #Set up the bandwidth limit for this network
          bandwidth_cmd << "tc class add dev #{nic} parent 1:1 classid 1:1#{nw[:bandwidth_mark]} htb rate #{nw[:bandwidth]}mbit ceil #{nw[:bandwidth]}mbit prio 1"
          bandwidth_cmd << "tc qdisc add dev #{nic} parent 1:1#{nw[:bandwidth_mark]} handle 1#{nw[:bandwidth_mark]}: sfq perturb 10"
          bandwidth_cmd << "tc filter add dev #{nic} protocol ip parent 1: prio 1 handle #{nw[:bandwidth_mark]} fw classid 1:1#{nw[:bandwidth_mark]}"

          #Mark the packets passing through this network
          ["s","d"].each { |x| bandwidth_cmd << "iptables -A FORWARD -#{x} #{nw[:ipv4_gw]}/#{nw[:prefix]} -j MARK --set-mark 0x#{nw[:bandwidth_mark]}" }
        }

        bandwidth_cmd
      end
    end

    module Nat
      include Dcmgr::Helpers::NicHelper
      include Dcmgr::Logger
      
      # Quick and dirty hack to unlink the nat chains before deleting them.
      # It would be cleaner to recall the creation method with a :delete action
      # but NAT rules are based on IP leases and those are deleted on instance termination
      # Therefore we use grep to get the referring rules based on vnic uuid and then delete them.
      # Run build_nat_chains(inst_map, :delete) afterwards to delete the chains themselves
      def unlink_nat_chains(inst_map)
        raise ArgumentError, "inst_map must be a Hash." unless inst_map.is_a?(Hash)

        del_cmds = []
        inst_map[:instance_nics].each { |nic|
          post = %x{iptables -t nat -L POSTROUTING --line-numbers | grep s_#{nic[:uuid]} | tr -s ' ' | cut -d ' ' -f1}.chomp
          pre = %x{iptables -t nat -L PREROUTING --line-numbers | grep d_#{nic[:uuid]} | tr -s ' ' | cut -d ' ' -f1}.chomp

          del_cmds << "iptables -t nat -D POSTROUTING #{post}" unless post.empty?
          del_cmds << "iptables -t nat -D PREROUTING #{pre}" unless pre.empty?
        }

        del_cmds
      end
      
      # Similar hack to unlink_nat_chains. Once an instance is terminated,
      # we no longer know which IP it had so we grep the rules by mac address
      # and delete them by rule numer
      def stop_arp_reply(inst_map)
        raise ArgumentError, "inst_map must be a Hash." unless inst_map.is_a?(Hash)

        del_cmds = []

        inst_map[:instance_nics].each { |nic|
          mac = clean_mac(nic[:mac_addr])
          rule_number = %x{ebtables -t nat -L --Ln --Lmac2 | grep #{mac} | cut -d '.' -f1}
          del_cmds << "ebtables -t nat -D PREROUTING #{rule_number}" unless rule_number.empty?
        }

        del_cmds
      end
      
      # Builds or deletes the chains for each vnic in an instance.
      # We use different chains for incoming and outgoing packets per vnic
      # This way every packet only needs to be checked against chains that
      # are specifically intended for it.
      # _inst_map_ is a map of the instance to build or delte chains for.
      # _action_ decides wether we will create or delete the rules. It can be
      # either of the following:
      # * :create is the default value and creates chains for _inst_map_
      # * :delete deletes the chains for _inst_map_
      def build_nat_chains(inst_map, action = :create)
        actions = { :create => ['N'], :delete => ['F', 'X'] }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}." unless actions.keys.member?(action)
        raise ArgumentError, "inst_map must be a Hash." unless inst_map.is_a?(Hash)

        chain_cmds = []
        inst_map[:instance_nics].each { |nic|
          ['s','d'].each { |bound|
            actions[action].each { |a|
              chain_cmds << "iptables -t nat -#{a} #{bound}_#{nic[:uuid]}"
            }
          }
        }

        chain_cmds
      end

      # Takes an instance and nats it.
      # If the instance is in a network that has a nat_network mapped to it,
      # it will receive a second ip lease for that network. This lease will then be
      # natted to the ip the instance already had in its own network.
      # For example if 192.168.0.0/24 is natted to 172.16.0.0/16, then
      # an instance with ip 192.168.0.10 might be natted to ip 172.16.46.23.
      def nat_instance(inst_map)
        raise ArgumentError, "inst_map must be a Hash." unless inst_map.is_a?(Hash)

        nat_cmd = []

        inst_map[:instance_nics].each { |nic|
          # strict check
          next unless valid_nic?(nic[:uuid])

          nat_ips = rpc.request('hva-collector', 'get_nat_leases', nic[:uuid]).map {|ip| IPAddress(ip)}

          #Get the internal ip for this nic
          internal_ip = IPAddress rpc.request('hva-collector', 'get_iplease_for_nic', nic[:uuid])
          inside_exception_ips = rpc.request('hva-collector','get_group_instance_ipv4s',inst_map[:uuid]).map {|ip| IPAddress(ip)}
          outside_exception_ips = rpc.request('hva-collector','get_group_instance_ipv4s',inst_map[:uuid],:outside).map {|ip| IPAddress(ip)}

          #output the commands to nat this nic and answer arp requests for its outside ip
          friend_ipset  = nic[:uuid] + "_friend_ips"
          nat_ips.each { |external_ip|
            if @node.manifest.config.use_ipset

              nat_cmd << "ipset -N #{friend_ipset} iphash"

              inside_exception_ips.each { |ex_ip|
                nat_cmd << "ipset -A #{friend_ipset} #{ex_ip.address}"
              }

              # The good rules that use ipset              
              postrouting_command = "iptables -t nat -A s_#{nic[:uuid]} -s #{internal_ip.address} -m set ! --match-set #{friend_ipset} dst"
              prerouting_command = "iptables -t nat -A d_#{nic[:uuid]} -d #{external_ip.address} -m set ! --match-set #{friend_ipset} src"
            else
              # The ugly rules to use in case ipset is not installed
              postrouting_command = "iptables -t nat -A s_#{nic[:uuid]} -s #{internal_ip.address}"
              prerouting_command = "iptables -t nat -A d_#{nic[:uuid]} -d #{external_ip.address}"
            end

            # Set up the proper chain jumps
            nat_cmd << "iptables -t nat -A PREROUTING -d #{external_ip.address} -j d_#{nic[:uuid]}"
            nat_cmd << "iptables -t nat -A POSTROUTING -s #{internal_ip.address} -j s_#{nic[:uuid]}"

            # Build the final nat rules and log any packets that traverse them
            nat_cmd << postrouting_command  + " -j LOG --log-prefix 'Snat '" if @node.manifest.config.packet_drop_log
            nat_cmd << postrouting_command  + " -j SNAT --to #{external_ip.address}"

            nat_cmd << prerouting_command + " -j LOG --log-prefix 'Dnat '" if @node.manifest.config.packet_drop_log
            nat_cmd << prerouting_command + " -j DNAT --to #{internal_ip.address}"

            logger.debug "Natting #{internal_ip.address} to #{external_ip.address}"

            mac = clean_mac(nic[:mac_addr])
            nat_cmd << arp_respond(external_ip,mac)
          }
        }

        nat_cmd
      end

      # Returns the netfilter rules for destination IP addresses that
      # will not use static nat. These are the IP addresses of other instances
      # in the same security group.
      # _inst_map_ is a map of the instance that the rules will be defined for.
      def nat_exceptions(inst_map)
        inside_exception_ips = rpc.request('hva-collector','get_group_instance_ipv4s',inst_map[:uuid]).map {|ip| IPAddress(ip)}
        outside_exception_ips = rpc.request('hva-collector','get_group_instance_ipv4s',inst_map[:uuid],:outside).map {|ip| IPAddress(ip)}

        cmds = []
        inst_map[:instance_nics].each { |nic|
          # strict check
          next unless valid_nic?(nic[:uuid])

          internal_ip = IPAddress(rpc.request('hva-collector', 'get_iplease_for_nic', nic[:uuid]))
          inside_exception_ips.each { |ex_ip|
            cmds << "iptables -t nat -A s_#{nic[:uuid]} -s #{internal_ip.address} -d #{ex_ip.address}/#{ex_ip.prefix} -j ACCEPT"
          }
          outside_exception_ips.each { |ex_ip|
            cmds << "iptables -t nat -A d_#{nic[:uuid]} -s #{internal_ip.address} -d #{ex_ip.address}/#{ex_ip.prefix} -j ACCEPT"
          }
        }

        cmds
      end

      # Returns ebtables command to respond to ARP requests for the address _ip_.
      # _mac_addr_ is the mac address that we will reply with.
      def arp_respond(ip,mac_addr)
        ip = IPAddress(ip) if ip.is_a?(String)
        raise "Invalid IP address: #{ip}" unless ip.is_a?(IPAddress)

        #Get the mac address for our physical nic
        #nic = find_nic(@node.manifest.config.hv_ifindex)
        #TODO: Find a prettier way to get the mac address
        #mac_addr = %x{ifconfig | grep '#{nic}' | tr -s ' ' | cut -d ' ' -f5}.chomp

        logger.debug "Replying ARP requests for address: #{ip.address}"

        "ebtables -t nat -A PREROUTING -p arp --arp-ip-dst #{ip.address} --arp-opcode REQUEST -j arpreply --arpreply-mac #{mac_addr}"
      end

      def is_natted_ip?(ip)
        ip = IPAddress(ip) if ip.is_a?(String)
        raise ArgumentError, "Invalid IP address: #{ip}" unless ip.is_a?(IPAddress)

        rpc.request('hva-collector', 'is_natted_ip?', ip.address)
      end
    end

    class ServiceNetfilter < Isono::NodeModules::Base
      include Dcmgr::Logger
      include Dcmgr::Helpers::NicHelper
      include Nat
      include Bandwidth
      
      attr_accessor :controller

      initialize_hook do
        @worker_thread = Isono::ThreadPool.new(1, 'Netfilter')

        event = Isono::NodeModules::EventChannel.new(node)

        if myinstance.node.manifest.config.edge_networking == 'legacy_netfilter'
          ##### Legacy netfilter part #####
          @worker_thread.pass {
            myinstance.init_netfilter
          }
          
          myinstance.subscribe_to_event('hva/instance_started') do |args|
            @worker_thread.pass {
              logger.info("refresh on instance_started: #{args.inspect}")
              inst_id = args[0]
              
              logger.info("add_netfilter_by_instance_id: #{inst_id}")
              myinstance.add_netfilter_by_instance_id(inst_id)
            }
          end
          
          myinstance.subscribe_to_event('hva/instance_terminated') do |args|
            @worker_thread.pass {
              logger.info("refresh on instance_terminated: #{args.inspect}")
              inst_id = args[0]
              
              logger.info("delete_netfilter_by_instance_id: #{inst_id}")
              myinstance.delete_netfilter_by_instance_id(inst_id)
            }
          end
          
          myinstance.subscribe_to_event('hva/security_group_updated') do |args|
            @worker_thread.pass {
              logger.info("refresh on netfilter_updated: #{args.inspect}")
              security_group_id = args[0]
              
              myinstance.refresh_netfilter_by_joined_security_group_id(security_group_id)
            }
          end
          
        else
          ##### VNet netfilter part #####
          @worker_thread.pass {
            sleep 1
            # Initializing the controller will also apply netfilter rules for every alive instance
            myinstance.controller = VNet::ControllerFactory.create_controller(myinstance.node)
            
            # Subscribe to the instance's security groups' event queues
            myinstance.controller.get_instances.each { |inst|
              inst[:vif].each { |vif|
                vif[:security_groups].each { |secg|
                  myinstance.subscribe_to_security_group(secg)
                }
              }
            }
          }
          
          myinstance.subscribe_to_event("hva.#{myinstance.node.manifest.node_instance_id}/instance_started") do |args|
            @worker_thread.pass {
              inst_id = args[0]
              logger.debug "event caught: hva.#{myinstance.node.manifest.node_instance_id}/instance_started: #{inst_id}"
              myinstance.controller.apply_instance(inst_id)
              
              # Subscribe to the instance's security groups' event queues
              inst = myinstance.controller.get_instances(inst_id)
              inst[:vif].each { |vif|
                vif[:security_groups].each { |secg|
                  myinstance.subscribe_to_security_group(secg)
                }
              }
            }
          end
          
          myinstance.subscribe_to_event("hva.#{myinstance.node.manifest.node_instance_id}/instance_terminated") do |args|
            @worker_thread.pass {
              inst_id = args[0]
              logger.debug "event caught: hva.#{myinstance.node.manifest.node_instance_id}/instance_terminated: #{inst_id}"
              
              # Unsubscribe from this instance's security groups' event queues if there aren't any other instances in them
              inst = myinstance.controller.get_instances(inst_id)
              other_insts_groups = myinstance.controller.get_instances.delete_if {|inst_map| inst_map[:uuid] == inst_id}.map { |inst_map|
                inst_map[:vif].map {|vif| vif[:security_groups]}
              }.flatten.uniq
              inst[:vif].each { |vif|
                vif[:security_groups].each { |secg|
                  myinstance.unsubscribe_from_security_group(secg) unless other_insts_groups.member?(secg)
                }
              }
              
              myinstance.controller.remove_instance(inst_id)
            }
          end
        end

        myinstance.subscribe_to_event('broadcast/debug/vnet') do |args|
          @worker_thread.pass {
            case args[0]
            when 'switch_info'
              result = { :type => 'netfilter' }
              event.publish('gather/debug/vnet', { :sender => args[1], :args => [args[0], myinstance.node.node_id, result] })
            end
          }
        end
      end

      def subscribe_to_event(ev,&blk)
        begin
          event.subscribe(ev,'#',&blk)
          logger.debug("Subscribing to: #{ev}")
        rescue AMQP::Error => e
          # Do nothing if we're already subscribed to this queue
          raise unless e.message == "already subscribed to the queue"
          #logger.debug("Already subscribed to: #{ev}")
        end
      end
      
      def unsubscribe_from_event(ev)
        logger.debug("Unsubscribing from: #{ev}")
        event.unsubscribe(ev)
      end

      def subscribe_to_security_group(group_id)
        subscribe_to_event("#{group_id}/vnic_joined") do |args|
          @worker_thread.pass {
            vnic_id = args[0]
            logger.debug "event caught: #{group_id}/vnic_joined: #{vnic_id}"
            controller.join_security_group(vnic_id,group_id)
          }
        end
        
        subscribe_to_event("#{group_id}/vnic_left") do |args|
          @worker_thread.pass {
            vnic_id = args[0]
            logger.debug "event caught: #{group_id}/vnic_left: #{vnic_id}"
            controller.leave_security_group(vnic_id,group_id)
          }
        end
        
        subscribe_to_event("#{group_id}/rules_updated") do |args|
          @worker_thread.pass {
            logger.debug "event caught: #{group_id}/rules_updated"
            controller.update_security_group(group_id)
          }
        end
      end

      def unsubscribe_from_security_group(group_id)
        unsubscribe_from_event("#{group_id}/vnic_joined")
        unsubscribe_from_event("#{group_id}/vnic_left")
        unsubscribe_from_event("#{group_id}/rules_updated")
      end

      def init_netfilter
        begin
          inst_maps = rpc.request('hva-collector', 'get_alive_instances', node.node_id)

          viftable_map = {}
          inst_maps = inst_maps.map { |inst_map|
            viftable_map[ inst_map[:ips].first ] = inst_map[:instance_nics].first[:uuid]

            # Does the hva have instance?
            unless inst_map[:host_node][:node_id] == node.node_id
              logger.warn("no match for the instance: #{inst_map[:uuid]}")
              next
            end
            # Does host have vif?
            next unless valid_nic?(inst_map[:instance_nics].first[:uuid])
            inst_maps
          }.flatten.uniq.compact

          init_iptables(inst_maps) if @node.manifest.config.enable_iptables
          init_ebtables(inst_maps, viftable_map) if @node.manifest.config.enable_ebtables
          init_static_nat(inst_maps) if @node.manifest.config.enable_iptables && @node.manifest.config.enable_ebtables
          init_bandwidth_limit(networks = rpc.request('hva-collector', 'get_networks')) if @node.manifest.config.enable_iptables
          sleep 1

          logger.info("initialized netfilter")
        rescue Exception => e
          p e
        end
      end

      # This method created all netfilter rules for one instance.
      # It is called when starting a new instances
      # _inst_id_ is the canonical uuid of the instance whose netfilter rule are to be created.
      def add_netfilter_by_instance_id(inst_id)
        raise ArgumentError, "Unknown Instance ID: #{inst_id}" if inst_id.nil?
        inst_map = rpc.request('hva-collector', 'get_instance', inst_id)
        raise ArgumentError, "Unknown Instance ID: #{inst_id}" if inst_map.nil?

        cmds = []
        vif_map = build_vif_map(inst_map)
        viftable_map = {}
        viftable_map[ inst_map[:ips].first ] = inst_map[:instance_nics].first[:uuid]

        if @node.manifest.config.enable_ebtables
          cmds << build_ebtables_chains(vif_map,:create)
          cmds << build_ebtables_basic_part(vif_map, inst_map, :create)
          cmds << build_ebtables_group_part(vif_map, inst_map, viftable_map, :create)
          cmds << build_ebtables_final_part(vif_map, :create)
        end

        if @node.manifest.config.enable_iptables
          cmds << build_iptables_chains(protocol_map(:iptables), vif_map, :create)
          cmds << build_iptables_basic_part(vif_map, inst_map, :create)
          cmds << build_iptables_group_part(vif_map, inst_map, :create)
          cmds << build_iptables_final_part(vif_map, :create)
        end

        if @node.manifest.config.enable_ebtables && @node.manifest.config.enable_iptables
          cmds << build_nat_chains(inst_map)
          cmds << nat_exceptions(inst_map) unless @node.manifest.config.use_ipset
          cmds << nat_instance(inst_map)
        end
        
        do_exec(cmds)
      end

      # This method deletes all netfilter rules for one instance.
      # It is called when terminating an instance.
      # _inst_id_ The canonical uuid of the instance whose netfilter rules are to be deleted.
      def delete_netfilter_by_instance_id(inst_id)
        raise ArgumentError, "Unknown Instance ID: #{inst_id}" if inst_id.nil?
        inst_map = rpc.request('hva-collector', 'get_instance', inst_id)
        raise ArgumentError, "Unknown Instance ID: #{inst_id}" if inst_map.nil?

        #Create vnic map
        vif_map = build_vif_map(inst_map)

        #Delete ebtables chains
        cmds = []

        #Calling build_ebtables_basic_part with the :delete flag will delete all jumps to this instance's chains and then delete the chains themselves
        cmds << build_ebtables_basic_part(vif_map, inst_map, :delete) if @node.manifest.config.enable_ebtables

        #Delete nat chains
        if @node.manifest.config.enable_ebtables && @node.manifest.config.enable_iptables
          cmds << unlink_nat_chains(inst_map)
          cmds << stop_arp_reply(inst_map)
          cmds << build_nat_chains(inst_map, :delete)
        end

        #Delete iptables chains
        cmds << build_iptables_basic_part(vif_map, inst_map, :delete) if @node.manifest.config.enable_iptables

        do_exec(cmds)
      end

      # from event_subscriber
      def refresh_netfilter_by_friend_instance_id(inst_id)
        raise "UnknownInstanceID" if inst_id.nil?

        begin
          ng_maps = rpc.request('hva-collector', 'get_security_groups_of_instance', inst_id)
          # get friend instance(s)
          friend_inst_maps = ng_maps.map { |ng_map|
            rpc.request('hva-collector', 'get_instances_of_security_group', ng_map[:id])
          }.flatten.uniq
          guest_inst_maps = rpc.request('hva-collector', 'get_alive_instances', node.node_id)

          uuids = friend_inst_maps.map { |inst_map| inst_map[:uuid] } & guest_inst_maps.map  { |inst_map| inst_map[:uuid] }
          logger.info("my guest instance(s)?: #{uuids.inspect}")

          if uuids.flatten.uniq.size > 0
            init_netfilter
          else
            # group_instance: 1->0
            inst_map = rpc.request('hva-collector', 'get_instance', inst_id)
            init_netfilter if inst_map[:host_node][:node_id] == node.node_id
          end
        rescue Exception => e
          p e
        end
      end

      # from event_subscriber
      def refresh_netfilter_by_joined_security_group_id(security_group_id)
        raise "Unknown security group ID: #{security_group_id}" if security_group_id.nil?

        begin
          inst_maps = rpc.request('hva-collector', 'get_instances_of_security_group', security_group_id)
          init_netfilter if inst_maps.size > 0
        rescue Exception => e
          p e
        end
      end

      def build_vif_map(inst_map = {})
        vif_map = {
          :uuid  => inst_map[:instance_nics].first[:uuid],
          :mac   => clean_mac(inst_map[:instance_nics].first[:mac_addr]),
          :ipv4  => inst_map[:ips].first,
        }
      end

      def protocol_map(type)
        case type
        when :iptables
          {
            'tcp'  => 'tcp',
            'udp'  => 'udp',
            'icmp' => 'icmp',
          }
        when :ebtables
          {
            'ip4'  => 'ip4',
            'arp'  => 'arp',
            #'ip6'  => 'ip6',
            #'rarp' => '0x8035',
          }
        end
      end

      def do_exec(cmds)
        recmds = []

        eos = "__EOS_#{Isono::Util.gen_id}___"
        recmds << "/bin/cat <<'#{eos}' | /bin/bash"
        cmds.flatten.uniq.each { |cmd|
          puts cmd if @node.manifest.config.verbose_netfilter == true
          recmds << cmd
        }
        recmds << "#{eos}"

        logger.debug("applying rule line(s): #{recmds.size - 2}")
        system(recmds.join("\n"))
        logger.debug("applied rule line(s): #{recmds.size - 2}")
      end

      def init_ebtables(inst_maps = [], viftable_map = {})
        init_cmds  = []
        basic_cmds = []
        group_cmds = []
        nat_cmds   = []
        final_cmds = []

        init_cmds << "ebtables --init-table"
        #Clear the nat table. This table is only used in build_ebtables_nat_part
        init_cmds << "ebtables -t nat --init-table"

        inst_maps.each { |inst_map|
          vif_map = build_vif_map(inst_map)

          basic_cmds << build_ebtables_basic_part(vif_map, inst_map)
          group_cmds << build_ebtables_group_part(vif_map, inst_map, viftable_map)
          final_cmds << build_ebtables_final_part(vif_map)
        }

        viftable_map.each { |k,v|
          logger.debug("viftable: #{v} <=> #{k}")
        }

        do_exec([init_cmds, basic_cmds, group_cmds, final_cmds])
      end

      def init_iptables(inst_maps = [])
        init_cmds  = []
        basic_cmds = []
        group_cmds = []
        nat_cmds   = []
        final_cmds = []

        #Drop all packets that aren't explicitely allowed
        #init_cmds << "iptables -P FORWARD DROP"
        init_cmds << "iptables -P FORWARD ACCEPT"

        [ 'raw', 'nat', 'filter' ].each { |table|
          [ 'F', 'Z', 'X' ].each { |xcmd|
            init_cmds << "iptables -t #{table} -#{xcmd}"
          }
        }

        if @node.manifest.config.use_ipset
          ['F','X'].each { |xcmd|
            init_cmds << "ipset -#{xcmd}"
          }
        end

        # via http://backreference.org/2010/06/11/iptables-debugging/
        # To debug ipv4 packets.
        # $ sudo tail -F /var/log/kern.log | grep TRACE:
        if @node.manifest.config.debug_iptables
          init_cmds << "iptables -t raw -A OUTPUT -p icmp -j TRACE"
          init_cmds << "iptables -t raw -A PREROUTING -p icmp -j TRACE"
        end

        inst_maps.each { |inst_map|
          vif_map = build_vif_map(inst_map)

          basic_cmds << build_iptables_basic_part(vif_map, inst_map)
          group_cmds << build_iptables_group_part(vif_map, inst_map)
          final_cmds << build_iptables_final_part(vif_map)
        }

        do_exec([init_cmds, basic_cmds, group_cmds, final_cmds])
      end

      def init_static_nat(inst_maps = [])
        chain_cmds  = []
        #ref_cmds    = []
        accept_cmds = []
        nat_cmds    = []

        inst_maps.each { |inst_map|
          chain_cmds  << build_nat_chains(inst_map)
          #ref_cmds    = ref_nat_chains(inst_map)
          accept_cmds << nat_exceptions(inst_map) unless @node.manifest.config.use_ipset
          nat_cmds    << nat_instance(inst_map)
        }

        do_exec([chain_cmds,accept_cmds,nat_cmds])
      end

      def init_bandwidth_limit(network_maps)
        do_exec([clear_bandwidth_limits,limit_bandwidth(network_maps)])
      end

      def build_ebtables_chains(vif_map,action = :create)
        actions = { :create => 'N' , :delete => 'X' }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}" unless actions.keys.member?(action)
        ################################
        ## 0. chain name
        ################################

        # support IP protocol
        protocol_map = protocol_map(:ebtables)

        # make chain names.
        chains = []
        chains << "s_#{vif_map[:uuid]}"
        chains << "d_#{vif_map[:uuid]}"
        chains << "s_#{vif_map[:uuid]}_d_hst"
        chains << "d_#{vif_map[:uuid]}_s_hst"
        protocol_map.each { |k,v|
          chains << "s_#{vif_map[:uuid]}_#{k}"
          chains << "d_#{vif_map[:uuid]}_#{k}"
          chains << "s_#{vif_map[:uuid]}_d_hst_#{k}"
          chains << "d_#{vif_map[:uuid]}_s_hst_#{k}"
        }

        # create user defined chains.
        cmds = chains.map { |chain|
          "ebtables -#{actions[action]} #{chain}"
        }

        cmds
      end

      def build_ebtables_basic_part(vif_map, inst_map, action = :create)
        basic_cmds = []

        actions = { :create => 'A' , :delete => 'D' }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}" unless actions.keys.member?(action)

        hva_ipv4 = Isono::Util.default_gw_ipaddr

        ################################
        ## 1. basic part
        ################################
        
        protocol_map = protocol_map(:ebtables)

        basic_cmds << build_ebtables_chains(vif_map,action) if action == :create

        # jumt to user defined chains
        basic_cmds << "ebtables -#{actions[action]} FORWARD -i #{vif_map[:uuid]} -j s_#{vif_map[:uuid]}"
        basic_cmds << "ebtables -#{actions[action]} FORWARD -o #{vif_map[:uuid]} -j d_#{vif_map[:uuid]}"
        basic_cmds << "ebtables -#{actions[action]} INPUT   -i #{vif_map[:uuid]} -j s_#{vif_map[:uuid]}_d_hst"
        basic_cmds << "ebtables -#{actions[action]} OUTPUT  -o #{vif_map[:uuid]} -j d_#{vif_map[:uuid]}_s_hst"

        # IP protocol routing
        protocol_map.each { |k,v|
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}       -p #{v} -j s_#{vif_map[:uuid]}_#{k}"
          basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}       -p #{v} -j d_#{vif_map[:uuid]}_#{k}"
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst -p #{v} -j s_#{vif_map[:uuid]}_d_hst_#{k}"
          basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_s_hst -p #{v} -j d_#{vif_map[:uuid]}_s_hst_#{k}"
        }

        if @node.manifest.config.packet_drop_log
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}       --log-level 4 --log-ip --log-arp --log-prefix 'D s_#{vif_map[:uuid]}:'       -j CONTINUE" if @node.manifest.config.packet_drop_log
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst --log-level 4 --log-ip --log-arp --log-prefix 'D s_#{vif_map[:uuid]}_d_hst:' -j CONTINUE" if @node.manifest.config.packet_drop_log
        end
        basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}       -j DROP"
        basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst -j DROP"
        # anti spoof: mac    # guest -> *
        basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_arp       --protocol arp --arp-mac-src ! #{vif_map[:mac]} --log-ip --log-arp --log-prefix 'Dmc s_#{vif_map[:uuid]}_arp:'       -j CONTINUE" if @node.manifest.config.packet_drop_log
        basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-mac-src ! #{vif_map[:mac]} --log-ip --log-arp --log-prefix 'Dmc s_#{vif_map[:uuid]}_d_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
        basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_arp       --protocol arp --arp-mac-src ! #{vif_map[:mac]} -j DROP"
        basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-mac-src ! #{vif_map[:mac]} -j DROP"
        # guest <- * (broadcast)
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp                          --arp-mac-dst 00:00:00:00:00:00 --log-ip --log-arp --log-prefix 'Amc d_#{vif_map[:uuid]}_arp:'     -j CONTINUE" if @node.manifest.config.packet_drop_log
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_s_hst_arp --protocol arp --arp-ip-src=#{hva_ipv4} --arp-mac-dst 00:00:00:00:00:00 --log-ip --log-arp --log-prefix 'Amc d_#{vif_map[:uuid]}_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp                          --arp-mac-dst 00:00:00:00:00:00 -j ACCEPT"
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_s_hst_arp --protocol arp --arp-ip-src=#{hva_ipv4} --arp-mac-dst 00:00:00:00:00:00 -j ACCEPT"

        # guest <- *
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp --arp-mac-dst ! #{vif_map[:mac]} --log-ip --log-arp --log-prefix 'Dmc d_#{vif_map[:uuid]}_arp:'       -j CONTINUE" if @node.manifest.config.packet_drop_log
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_s_hst_arp --protocol arp --arp-mac-dst ! #{vif_map[:mac]} --log-ip --log-arp --log-prefix 'Dmc d_#{vif_map[:uuid]}_s_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp --arp-mac-dst ! #{vif_map[:mac]} -j DROP"
        basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_s_hst_arp --protocol arp --arp-mac-dst ! #{vif_map[:mac]} -j DROP"

        # anti spoof: ipv4
        inst_map[:ips].each { |ipv4|
          # guest -> *
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_arp       --protocol arp --arp-ip-src ! #{ipv4} --log-ip --log-arp --log-prefix 'Dip s_#{vif_map[:uuid]}_arp:'       -j CONTINUE" if @node.manifest.config.packet_drop_log
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-ip-src ! #{ipv4} --log-ip --log-arp --log-prefix 'Dip s_#{vif_map[:uuid]}_d_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_arp       --protocol arp --arp-ip-src ! #{ipv4} -j DROP"
          basic_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-ip-src ! #{ipv4} -j DROP"
          # guest <- *
          basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp --arp-ip-dst ! #{ipv4} --log-ip --log-arp --log-prefix 'Dip d_#{vif_map[:uuid]}_arp:'       -j CONTINUE" if @node.manifest.config.packet_drop_log
          basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_s_hst_arp --protocol arp --arp-ip-dst ! #{ipv4} --log-ip --log-arp --log-prefix 'Dip d_#{vif_map[:uuid]}_s_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
          basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp --arp-ip-dst ! #{ipv4} -j DROP"
          basic_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_s_hst_arp --protocol arp --arp-ip-dst ! #{ipv4} -j DROP"
        }

        basic_cmds << build_ebtables_chains(vif_map,action) if action == :delete
        basic_cmds
      end

      def build_ebtables_group_part(vif_map, inst_map, viftable_map, action = :create)
        group_cmds = []
        hva_ipv4 = Isono::Util.default_gw_ipaddr
        actions = { :create => 'A' , :delete => 'D' }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}" unless actions.keys.member?(action)

        ################################
        ## 2. group part
        ################################
        same_subnet_ipv4s = rpc.request('hva-collector', 'get_group_instance_ipv4s', inst_map[:uuid])

        network_map = rpc.request('hva-collector', 'get_network', inst_map[:instance_nics].first[:network_id])
        raise "UnknownNetworkId" if network_map.nil?
        joined_network = IPAddress("#{network_map[:ipv4_gw]}/#{network_map[:prefix]}")

        [ network_map[:dns_server], network_map[:dhcp_server], network_map[:metadata_server] ].each { |ipv4|
          next if ipv4.nil? or not joined_network.include? IPAddress(ipv4)
          same_subnet_ipv4s << ipv4
        }

        # network resource node(s)
        ng_maps = rpc.request('hva-collector', 'get_security_groups_of_instance', inst_map[:uuid])
        rules = ng_maps.map { |ng_map|
          ng_map[:rules].map { |rule| rule[:permission] }
        }.flatten
        build_rule(rules).each do |rule|
          # <ArgumentError: Invalid IP "0.0.0.0">
          next if rule[:ip_source] == "0.0.0.0/0"

          begin
            next unless joined_network.include? IPAddress(rule[:ip_source])
            same_subnet_ipv4s << rule[:ip_source]
          rescue Exception => e
            #raise unless e.is_a? ArgumentError
            p e
          end
        end
        same_subnet_ipv4s << network_map[:ipv4_gw]

        # guest node(s) in HyperVisor.
        alive_inst_maps = rpc.request('hva-collector', 'get_alive_instances', node.node_id)
        guest_ipv4s = alive_inst_maps.map { |alive_inst_map|
          alive_inst_map[:ips]
        }.flatten.uniq.compact

        same_subnet_ipv4s.uniq.reverse_each do |ipv4|
          next if vif_map[:ipv4] == ipv4

          # get_macaddr_by_ipv4, ipv4
          if ipv4 == hva_ipv4
            #p "#{vif_map[:uuid]}(#{vif_map[:ipv4]}) -> [host] ***-****** (#{ipv4})"
            group_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-ip-src #{vif_map[:ipv4]} --arp-ip-dst #{ipv4} --log-ip --log-arp --log-prefix 'Afw s_#{vif_map[:uuid]}_d_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
            group_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-ip-src #{vif_map[:ipv4]} --arp-ip-dst #{ipv4} -j ACCEPT"
          elsif guest_ipv4s.include?(ipv4)
            #p "#{vif_map[:uuid]}(#{vif_map[:ipv4]}) -> [guest] #{viftable_map[ipv4]}(#{ipv4})"

            # guest->guest
            group_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp --arp-ip-src #{ipv4} --arp-ip-dst #{vif_map[:ipv4]} --log-ip --log-arp --log-prefix 'Afw d_#{vif_map[:uuid]}_arp:'       -j CONTINUE" if @node.manifest.config.packet_drop_log
            group_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --protocol arp --arp-ip-src #{ipv4} --arp-ip-dst #{vif_map[:ipv4]} -j ACCEPT"
            # guest->host
            group_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-ip-src #{vif_map[:ipv4]} --arp-ip-dst #{ipv4} --log-ip --log-arp --log-prefix 'Afw s_#{vif_map[:uuid]}_d_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
            group_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --protocol arp --arp-ip-src #{vif_map[:ipv4]} --arp-ip-dst #{ipv4} -j ACCEPT"

            unless viftable_map[ipv4].nil?
              # guest->guest
              group_cmds << "ebtables -#{actions[action]} d_#{viftable_map[ipv4]}_arp       --protocol arp --arp-ip-src #{vif_map[:ipv4]} --arp-ip-dst #{ipv4} --log-ip --log-arp --log-prefix 'Arv d_#{viftable_map[ipv4]}_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
              group_cmds << "ebtables -#{actions[action]} d_#{viftable_map[ipv4]}_arp       --protocol arp --arp-ip-src #{vif_map[:ipv4]} --arp-ip-dst #{ipv4} -j ACCEPT"

              # guest->host
              group_cmds << "ebtables -#{actions[action]} s_#{viftable_map[ipv4]}_d_hst_arp --protocol arp --arp-ip-src #{ipv4} --arp-ip-dst #{vif_map[:ipv4]} --log-ip --log-arp --log-prefix 'Arv s_#{viftable_map[ipv4]}_d_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
              group_cmds << "ebtables -#{actions[action]} s_#{viftable_map[ipv4]}_d_hst_arp --protocol arp --arp-ip-src #{ipv4} --arp-ip-dst #{vif_map[:ipv4]} -j ACCEPT"
            end
          else
            #p "#{vif_map[:uuid]}(#{vif_map[:ipv4]}) -> [other] ***-******** (#{ipv4})"
            group_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp --protocol arp --arp-ip-src #{ipv4} --arp-ip-dst #{vif_map[:ipv4]} --log-ip --log-arp --log-prefix 'Afw :d_#{vif_map[:uuid]}_arp' -j CONTINUE" if @node.manifest.config.packet_drop_log
            group_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp --protocol arp --arp-ip-src #{ipv4} --arp-ip-dst #{vif_map[:ipv4]} -j ACCEPT"
          end
        end

        group_cmds
      end

      def build_ebtables_final_part(vif_map, action = :create)
        final_cmds = []
        actions = { :create => 'A' , :delete => 'D' }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}" unless actions.keys.member?(action)

        ################################
        ## 3. final part
        ################################
        # deny,allow
        final_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       --log-level 4 --log-ip --log-arp --log-prefix 'D d_#{vif_map[:uuid]}_arp:'       -j CONTINUE" if @node.manifest.config.packet_drop_log
        final_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp --log-level 4 --log-ip --log-arp --log-prefix 'D s_#{vif_map[:uuid]}_d_hst_arp:' -j CONTINUE" if @node.manifest.config.packet_drop_log
        final_cmds << "ebtables -#{actions[action]} d_#{vif_map[:uuid]}_arp       -j DROP"
        final_cmds << "ebtables -#{actions[action]} s_#{vif_map[:uuid]}_d_hst_arp -j DROP"

        final_cmds
      end

      def build_iptables_chains(protocol_map, vif_map, action = :create)
        actions = { :create => ['N'] , :delete => ['F','X'] }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}" unless actions.keys.member?(action)

        chain_cmds = []

        ################################
        ## 0. chain name
        ################################

        [ 's', 'd' ].each do |bound|
          protocol_map.each { |k,v|
            actions[action].each do |act|
              chain_cmds << "iptables -#{act} #{bound}_#{vif_map[:uuid]}"
              chain_cmds << "iptables -#{act} #{bound}_#{vif_map[:uuid]}_#{k}"

              chain_cmds << "iptables -#{act} #{bound}_#{vif_map[:uuid]}_drop"
              chain_cmds << "iptables -#{act} #{bound}_#{vif_map[:uuid]}_#{k}_drop"
            end
          }
        end

        chain_cmds
      end

      def build_iptables_basic_part(vif_map, inst_map, action = :create)
        basic_cmds = []

        actions = { :create => 'A' , :delete => 'D' }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}" unless actions.keys.member?(action)

        network_map = rpc.request('hva-collector', 'get_network', inst_map[:instance_nics].first[:network_id])
        raise "UnknownNetworkId" if network_map.nil?

        # support IP protocol
        protocol_map = protocol_map(:iptables)

        # make chain names.
        basic_cmds << build_iptables_chains(protocol_map, vif_map, :create) if action == :create

        ################################
        ## 1. basic part
        ################################

        # metadata-server
        port = network_map[:metadata_server_port] || 80
        basic_cmds << "iptables -t nat -#{actions[action]} PREROUTING -m physdev --physdev-in #{vif_map[:uuid]} -d 169.254.169.254 -p tcp --dport 80 -j DNAT --to-destination #{network_map[:metadata_server]}:#{port}"

        # DHCP Server
        basic_cmds << "iptables -#{actions[action]} d_#{vif_map[:uuid]} -p udp ! -s #{network_map[:dhcp_server]} --sport 67 -j d_#{vif_map[:uuid]}_udp_drop"
        basic_cmds << "iptables -#{actions[action]} d_#{vif_map[:uuid]} -p udp ! -s #{network_map[:dhcp_server]} --sport 68 -j d_#{vif_map[:uuid]}_udp_drop"

        # group nodes
        # group node IPv4 addresses.
        ipv4s = rpc.request('hva-collector', 'get_group_instance_ipv4s', inst_map[:uuid])
        ipv4s << network_map[:ipv4_gw]
        ipv4s.uniq.reverse_each { |addr|
          basic_cmds << "iptables -#{actions[action]} d_#{vif_map[:uuid]} -s #{addr} -j ACCEPT"
        }

        # IP protocol routing
        [ 's', 'd' ].each do |bound|
          protocol_map.each { |k,v|
            #basic_cmds << "iptables -#{chain_actions[action]} #{bound}_#{vif_map[:uuid]}_#{k}"
            # Log dropped packets
            ["#{bound}_#{vif_map[:uuid]}", "#{bound}_#{vif_map[:uuid]}_#{k}"].each { |chain|
              basic_cmds << "iptables -#{actions[action]} #{chain}_drop -j LOG --log-level 4 --log-prefix 'D #{chain}:'" if @node.manifest.config.packet_drop_log
              basic_cmds << "iptables -#{actions[action]} #{chain}_drop -j DROP"
            }

            case k
            when 'tcp'
              case bound
              when 's'
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -m state --state NEW,ESTABLISHED -p #{k} -j #{bound}_#{vif_map[:uuid]}_#{k}"
              when 'd'
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -m state --state RELATED,ESTABLISHED -p #{k} -j ACCEPT"
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -p #{k} -j #{bound}_#{vif_map[:uuid]}_#{k}"
              end
            when 'udp'
              case bound
              when 's'
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -m state --state NEW,ESTABLISHED -p #{k} -j #{bound}_#{vif_map[:uuid]}_#{k}"
              when 'd'
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -m state --state ESTABLISHED -p #{k} -j ACCEPT"
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -p #{k} -j #{bound}_#{vif_map[:uuid]}_#{k}"
              end
            when 'icmp'
              case bound
              when 's'
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -m state --state NEW,ESTABLISHED,RELATED -p #{k} -j #{bound}_#{vif_map[:uuid]}_#{k}"
              when 'd'
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -m state --state ESTABLISHED,RELATED -p #{k} -j ACCEPT"
                basic_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -p #{k} -j #{bound}_#{vif_map[:uuid]}_#{k}"
              end
            end
          }
        end

        basic_cmds << "iptables -#{actions[action]} FORWARD -m physdev --physdev-is-bridged --physdev-in  #{vif_map[:uuid]} -j s_#{vif_map[:uuid]}"
        basic_cmds << "iptables -#{actions[action]} FORWARD -m physdev --physdev-is-bridged --physdev-out #{vif_map[:uuid]} -j d_#{vif_map[:uuid]}"

        ##
        ## ACCEPT
        ##
        # DHCP Server
        basic_cmds << "iptables -#{actions[action]} d_#{vif_map[:uuid]}_udp -p udp -s #{network_map[:dhcp_server]} --sport 67 -j ACCEPT"
        basic_cmds << "iptables -#{actions[action]} d_#{vif_map[:uuid]}_udp -p udp -s #{network_map[:dhcp_server]} --sport 68 -j ACCEPT"

        # DNS Server
        basic_cmds << "iptables -#{actions[action]} s_#{vif_map[:uuid]}_udp -p udp -d #{network_map[:dns_server]} --dport 53 -j ACCEPT"

        # MetaData Server
        basic_cmds << "iptables -#{actions[action]} s_#{vif_map[:uuid]}_tcp -p tcp -d #{network_map[:metadata_server]} --dport #{network_map[:metadata_server_port]} -j ACCEPT"

        ##
        ## DROP
        ##
        protocol_map.each { |k,v|
          # DHCP
          basic_cmds << "iptables -#{actions[action]} s_#{vif_map[:uuid]} -d #{network_map[:dhcp_server]} -p #{k} -j s_#{vif_map[:uuid]}_#{k}_drop"
          # DNS
          basic_cmds << "iptables -#{actions[action]} s_#{vif_map[:uuid]} -d #{network_map[:dns_server]} -p #{k} -j s_#{vif_map[:uuid]}_#{k}_drop"
        }

        basic_cmds << build_iptables_chains(protocol_map, vif_map, :delete) if action == :delete

        basic_cmds
      end

      def build_iptables_group_part(vif_map, inst_map, action = :create)
        group_cmds = []

        ################################
        ## 2. group part
        ################################
        
        case action
          when :delete
            protocol_map(:iptables).each { |k,v|
              # Fluch all security group chains
              group_cmds << "iptables -A d_#{vif_map[:uuid]}_#{k} -F"
            }
          when :create
            ng_maps = rpc.request('hva-collector', 'get_security_groups_of_instance', inst_map[:uuid])
            rules = ng_maps.map { |ng_map|
              ng_map[:rules].map { |rule| rule[:permission] }
            }.flatten

            # security group
            build_rule(rules).each do |rule|
              case rule[:ip_protocol]
              when 'tcp', 'udp'
                if rule[:ip_fport] == rule[:ip_tport]
                  group_cmds << "iptables -A d_#{vif_map[:uuid]}_#{rule[:ip_protocol]} -p #{rule[:ip_protocol]} -s #{rule[:ip_source]} --dport #{rule[:ip_fport]} -j ACCEPT"
                else
                  group_cmds << "iptables -A d_#{vif_map[:uuid]}_#{rule[:ip_protocol]} -p #{rule[:ip_protocol]} -s #{rule[:ip_source]} --dport #{rule[:ip_fport]}:#{rule[:ip_tport]} -j ACCEPT"
                end
              when 'icmp'
                # icmp
                #   This extension can be used if `--protocol icmp' is specified. It provides the following option:
                #   [!] --icmp-type {type[/code]|typename}
                #     This allows specification of the ICMP type, which can be a numeric ICMP type, type/code pair, or one of the ICMP type names shown by the command
                #      iptables -p icmp -h
                if rule[:icmp_type] == -1 && rule[:icmp_code] == -1
                  group_cmds << "iptables -A d_#{vif_map[:uuid]}_#{rule[:ip_protocol]} -p #{rule[:ip_protocol]} -s #{rule[:ip_source]} -j ACCEPT"
                else
                  group_cmds << "iptables -A d_#{vif_map[:uuid]}_#{rule[:ip_protocol]} -p #{rule[:ip_protocol]} -s #{rule[:ip_source]} --icmp-type #{rule[:icmp_type]}/#{rule[:icmp_code]} -j ACCEPT"
                end
              end
            end
          else
            raise ArgumentError, "#{action} is not a valid action."
        end
        group_cmds
      end

      def build_iptables_final_part(vif_map, action = :create)
        actions = { :create => 'A' , :delete => 'D' }
        raise ArgumentError, "#{action} is not a valid action. Valid actions are #{actions.keys.join(',')}" unless actions.keys.member?(action)

        final_cmds = []

        # support IP protocol
        protocol_map = protocol_map(:iptables)

        ################################
        ## 3. final part
        ################################

        # Send dropped ip packets to their respective drop chains, based on their protocol
        [ 'd' ].each do |bound|
          protocol_map.each { |k,v|
            # Any packets that travel the protocol specific chains and don't get accepted are directed to drop chains
            # where logging can take place before the packets are dropped by the FORWARD chain policy
            final_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]} -p #{k} -j #{bound}_#{vif_map[:uuid]}_#{k}_drop"
          }
        end

        # Allow outgoing traffic from the instance
        [ 's' ].each do |bound|
          protocol_map.each { |k,v|
            final_cmds << "iptables -#{actions[action]} #{bound}_#{vif_map[:uuid]}_#{k} -p #{k} -j ACCEPT"
          }
        end

        final_cmds
      end

      def build_rule(rules = [])
        rule_maps = []

        rules.each do |rule|
          rule = rule.strip.gsub(/[\s\t]+/, '')
          from_group = false
          ipv4s = []

          # ex.
          # "tcp:22,22,ip4:0.0.0.0"
          # "udp:53,53,ip4:0.0.0.0"
          # "icmp:-1,-1,ip4:0.0.0.0"

          # 1st phase
          # ip_tport    : tcp,udp? 1 - 16bit, icmp: -1
          # id_port has been separeted in first phase.
          from_pair, ip_tport, source_pair = rule.split(',')

          next if from_pair.nil?
          next if ip_tport.nil?
          next if source_pair.nil?

          # 2nd phase
          # ip_protocol : [ tcp | udp | icmp ]
          # ip_fport    : tcp,udp? 1 - 16bit, icmp: -1
          ip_protocol, ip_fport = from_pair.split(':')

          # protocol    : [ ip4 | ip6 | security_group_uuid ]
          # ip_source   : ip4? xxx.xxx.xxx.xxx./[0-32], ip6? (not yet supprted)
          protocol, ip_source = source_pair.split(':')

          begin
            s = StringScanner.new(protocol)
            until s.eos?
              case
              when s.scan(/ip6/)
                # TODO#FUTURE: support IPv6 address format
                next
              when s.scan(/ip4/)
                # IPAddress doesn't support prefix '0'.
                ip_addr, prefix = ip_source.split('/', 2)
                if prefix.to_i == 0
                  ip_source = ip_addr
                end
              when s.scan(/ng-\w+/)
                from_group = true
                inst_maps = rpc.request('hva-collector', 'get_instances_of_security_group', protocol)
                inst_maps.each { |inst_map|
                  ipv4s << inst_map[:ips]
                }
              else
                raise "unexpected protocol '#{s.peep(20)}'"
              end
            end
          rescue Exception => e
            p e
            next
          end

          begin
            if from_group == false
              #p "from_group:(#{from_group}) ip_source -> #{ip_source}"
              ip = IPAddress(ip_source)
              ip_source = case ip.u32
                          when 0
                            "#{ip.address}/0"
                          else
                            "#{ip.address}/#{ip.prefix}"
                          end
            else
              ipv4s = ipv4s.flatten.uniq
            end
          rescue Exception => e
            p e
            next
          end

          case ip_protocol
          when 'tcp', 'udp'
            ip_fport = ip_fport.to_i
            ip_tport = ip_tport.to_i

            # validate port range
            [ ip_fport, ip_tport ].each do |port|
              next unless port >= 1 && port <= 65535
            end

            if ip_fport <= ip_tport
              if from_group == false
                rule_maps << {
                  :ip_protocol => ip_protocol,
                  :ip_fport    => ip_fport,
                  :ip_tport    => ip_tport,
                  :protocol    => protocol,
                  :ip_source   => ip_source,
                }
              else
                ipv4s.each { |ip|
                  rule_maps << {
                    :ip_protocol => ip_protocol,
                    :ip_fport    => ip_fport,
                    :ip_tport    => ip_tport,
                    :protocol    => 'ip4',
                    :ip_source   => ip,
                  }
                }
              end
            end
          when 'icmp'
            # via http://docs.amazonwebservices.com/AWSEC2/latest/CommandLineReference/
            #
            # For the ICMP protocol, the ICMP type and code must be specified.
            # This must be specified in the format type:code where both are integers.
            # Type, code, or both can be specified as -1, which is a wildcard.

            icmp_type = ip_fport.to_i
            icmp_code = ip_tport.to_i

            # icmp_type
            case icmp_type
            when -1
            when 0, 3, 5, 8, 11, 12, 13, 14, 15, 16, 17, 18
            else
              next
            end

            # icmp_code
            case icmp_code
            when -1
            when 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
              # when icmp_type equals -1 icmp_code must equal -1.
              next if icmp_type == -1
            else
              next
            end

            if from_group == false
              rule_maps << {
                :ip_protocol => ip_protocol,
                :icmp_type   => ip_tport.to_i, # ip_tport.to_i, # -1 or 0,       3,    5,       8,        11, 12, 13, 14, 15, 16, 17, 18
                :icmp_code   => ip_fport.to_i, # ip_fport.to_i, # -1 or 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
                :protocol    => protocol,
                :ip_source   => ip_source,
              }
            else
              ipv4s.each { |ip|
                rule_maps << {
                  :ip_protocol => ip_protocol,
                  :icmp_type   => ip_tport.to_i, # ip_tport.to_i, # -1 or 0,       3,    5,       8,        11, 12, 13, 14, 15, 16, 17, 18
                  :icmp_code   => ip_fport.to_i, # ip_fport.to_i, # -1 or 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15
                  :protocol    => 'ip4',
                  :ip_source   => ip,
                }
              }
            end
          end
        end

        rule_maps
      end

      def rpc
        @rpc ||= Isono::NodeModules::RpcChannel.new(@node)
      end

      def event
        @event ||= Isono::NodeModules::EventChannel.new(@node)
      end

    end
  end
end
