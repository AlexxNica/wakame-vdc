# -*- coding: utf-8 -*-
require 'isono'
require 'dcmgr/helpers/zabbix_json_rpc'

module Dcmgr
  module NodeModules
    class HaManager < Isono::NodeModules::Base
      include Dcmgr::Logger

      initialize_hook do
        @thread_pool = Isono::ThreadPool.new(1, 'HA_Monitor')
        event = Isono::NodeModules::EventChannel.new(node)
        event.subscribe('hva/fault_instance', '#') { |args|
          @thread_pool.pass {
            inst_id = args[0]

            inst = rpc.request('hva-collector', 'get_instance', inst_id)
            # Here may get the event from the instances that no longer
            # exits on the database.
            if inst.nil?
              logger.error("Received fault instance event from unknown instance: #{inst_id}")
              next
            end

            # check if the instance has HA enable.
            if inst.ha_enabled == 0
              next
            else
              myinstance.restart_instance(inst)
            end
          }
        }

        # HostNode failure detection
        if Dcmgr.conf.instance_ha.monitor_script_path
          EM.add_periodic_timer(Dcmgr.conf.instance_ha.monitor_frequency_sec) {
            @thread_pool.pass {
              #myinstance.monitor_host_node_external
            }
          }
        end

        @monitor_target = MonitorTarget.new
        monitor_target_conf = Dcmgr.conf.monitor_target
        if monitor_target_conf
          monitor_target_conf.monitor_items.each { |name, mi|
            @monitor_target.add_monitor_item(name, mi)
          }

          if monitor_target_conf.conditions.is_a?(Proc)
            @monitor_target.condition.parse_dsl(&monitor_target_conf.conditions)
            @monitor_target.condition.result_proc do |result, context|
              if result == :failure
                myinstance.send_evacuation_request(context[:host_uuid])
              end
            end
          end
        end

        @monitor_target.monitor_items.values.each { |mi|
          mi = mi[:monitor_item]
          EM.add_periodic_timer(mi.poll_wait_sec) {
            @thread_pool.pass {
              myinstance.run_monitor_target_item(mi)
            }
          }
        }
      end

      terminate_hook do
        @thread_pool.shutdown
      end

      def run_monitor_target_item(monitor_item)
        host_node_lst = rpc.request('hva-collector', 'get_external_monitor_target_host_nodes')
        host_node_lst.each { |host_uuid|
          monitor_item.poll(host_uuid)
        }
      end

      def send_evacuation_request(host_uuid)
        jobrpc.submit("scheduler", 'evacuate_from',
                      host_uuid, true)
      end

      class MonitorTarget
        attr_reader :monitor_items, :condition

        def initialize
          @monitor_items = {}
          @condition = Condition.new
        end

        def add_monitor_item(name, monitor_item, opts={})
          if @monitor_items.has_key?(name)
            raise "Duplicate monitor item name: #{name}"
          end

          opts = {:history_size=>100}.merge(opts)

          @monitor_items[name] = {
            :monitor_item=>monitor_item,
            :history => SizedArray.new(opts[:history_size].to_i),
          }
          monitor_item.trigger = trigger = Trigger.new(self, name)
        end

        def add_history(monitor_item_name, row_data)
          unless @monitor_items.has_key?(monitor_item_name)
            raise ArgumentError, 'monitor_item_name'
          end
          @monitor_items[monitor_item_name][:history] << row_data
        end

        require 'forwardable'
        class SizedArray
          extend Forwardable
          include Enumerable
          attr_reader :max_size

          def_delegators(:@array, :each, :pop, :shift, :empty?, :clear,
                         :[], :[]=, :size)

          def initialize(max_size)
            @array = Array.new
            @max_size = max_size
          end

          def push(*obj)
            if @array.size + obj.size >= @max_size
              @array.shift(obj.size)
            end
            @array.push(*obj)
          end

          def unshift(*obj)
            # truncate 
            if @array.size + obj.size >= @max_size
              @array.pop(obj.size)
            end
            @array.unshift(*obj)
          end

          def <<(obj)
            push(obj)
          end
        end

        class HistoryModel
          def initialize(monitor_target, host_uuid)
            @monitor_target = monitor_target
            @host_uuid = host_uuid
          end

          def query(monitor_item_name, &blk)
            @monitor_target.monitor_items[monitor_item_name][:history].find_all { |r|
              r[:host_uuid] == @host_uuid
            }
          end

          def size(monitor_item_name)
            query(monitor_item_name).size
          end
        end

        def evaluate_condition(host_uuid)
          history_model = HistoryModel.new(self, host_uuid)
          @condition.walk({:history=>history_model, :host_uuid=>host_uuid})
        end
      end

      class Condition
        attr_reader :root_node

        def initialize
          @root_node = RootNode.new(self)
          @result_proc = nil
        end

        def result_proc(&blk)
          @result_proc = blk
        end

        def walk(context)
          _walk(@root_node, context)
        end

        def _walk(node, context)
          results = []
          node.children.each { |child|
            results << _walk(child, context)
          }
          node.evaluate(results, context)
        end

        def process_result(result, context)
          if @result_proc
            @result_proc.call(result.first, context)
          end
        end

        def parse_dsl(&blk)
          Builder.new(self).parse_dsl(&blk)
        end

        class Builder
          def self.register_dsl(dsl_module=nil, &blk)
            if !dsl_module.nil?
              DSLProxy.__send__(:include, dsl_module)
            elsif blk
              DSLProxy.class_eval(&blk)
            end
          end

          def initialize(condition)
            @condition = condition
          end

          def parse_dsl(&blk)
            DSLProxy.new(self).instance_exec(&blk)
          end

          class DSLProxy < BasicObject
            def initialize(builder)
              @builder = builder
            end
          end

          module DSLMethods
            def monitor_item(name)
              @builder.insert_node(MonitorItemNode.new(name))
            end
          end
          register_dsl DSLMethods

          def insert_node(node)
            if @condition.root_node.children.size > 0
              @condition.root_node.children.each { |child|
                node.children << child
              }
              @condition.root_node.children.clear
            end
            @condition.root_node.children << node
          end
        end
        
        class Node
          attr_reader :children

          def initialize()
            @children = []
          end

          def evaluate(result, context)
            result
          end
        end

        class LastNtimeNode < Node
          Builder.register_dsl do
            def last_ntimes_failure(ntimes, monitor_item_name)
              @builder.insert_node(LastNtimeNode.new(:failure, ntimes, monitor_item_name))
            end
          end

          def initialize(result, ntimes, monitor_item_name)
            super()

            unless ntimes.to_i > 0
              raise ArgumentError, "ntimes must be larger than 0"
            end
            @result = result
            @ntimes = ntimes
            @monitor_item_name = monitor_item_name
          end

          def evaluate(result, context)
            last_n_items = context[:history].query(@monitor_item_name).first(@ntimes)
            if last_n_items.size >= @ntimes.to_i
              last_n_items.all? { |i| i[:value] == @result } ? :failure : :success
            else
              :success
            end
          end
        end

        class MonitorItemNode < Node
          attr_reader :monitor_item_name
          
          def initialize(monitor_item_name)
            super()
            @monitor_item_name = monitor_item_name
          end
          
          def evaluate(result, context)
            context[:monitor_item_name] = @monitor_item_name
            first_row = context[:history].query(@monitor_item_name).first
            if first_row
              return first_row[:value]
            else
              return :failure
            end
          end
        end

        class RootNode < Node
          attr_reader :condition

          def initialize(condition)
            super()
            @condition = condition
          end

          def evaluate(result, context)
            @condition.process_result(result, context)
          end
        end

        class AndNode < Node
          Builder.register_dsl do
            def op_and(*sdfsdf)
              @builder.insert_node(AndNode.new(*sdfsdf))
            end
          end

          def initialize(*cond)
            super()
          end

          def evaluate(result, context)
            result1 = result.first
            result.all? { |i| i == result1 } ? :success : :failure
          end
        end
      end

      class Trigger
        def initialize(monitor_target, item_name)
          @monitor_target = monitor_target
          @item_name = item_name
        end

        def success(host_uuid)
          @monitor_target.add_history(@item_name, {:value=>:success, :host_uuid=>host_uuid})
          @monitor_target.evaluate_condition(host_uuid)
        end

        def failure(host_uuid)
          @monitor_target.add_history(@item_name, {:result=>:failure, :host_uuid=>host_uuid})
          @monitor_target.evaluate_condition(host_uuid)
        end
      end

      class MonitorItem
        attr_reader :poll_wait_sec
        attr_accessor :trigger

        def poll(host_uuid, opts={})
        end

        class Script < MonitorItem
          def initialize(script_path)
            @poll_wait_sec = 3
            @script_path = script_path
          end

          def poll(host_uuid, opts={})
            system("#{@script_path} #{host_uuid}")
            case $?.exitstatus
            when 0
              trigger.success(host_uuid)
            when 100
              trigger.failure(host_uuid)
            else
            end
          end
        end

        class ZabbixAPI < MonitorItem
          include Dcmgr::Logger
          include Dcmgr::Helpers::ZabbixJsonRpc
          attr_reader :conf

          def initialize(conf)
            @poll_wait_sec = 3
            @conf = conf
            @json_rpc_connection = Connection.new(conf[:api_uri], conf[:api_user], conf[:api_password])
          end

          def poll(host_uuid, opts={})
            res = rpc_request('host.get', {:filter=>{:host=>host_uuid}, :output=>'extend', :limit=>1})
            res = res.result.first
            if res.nil?
              raise "Failed to get response from host.get :filter=>{:host=>'#{host_uuid}'}"
            end
            hostid = res['hostid']
            trigger_name = conf[:trigger_name]

            res = rpc_request('trigger.get', {:filter=>{:description=>trigger_name}, :hostids=>[hostid], :output=>'extend', :limit=>1})
            res = res.result.first
            if res['status'].to_i == 0
              if res['value'].to_i == 0
                trigger.success(host_uuid)
              else
                trigger.failure(host_uuid)
              end
            else
              # skip to call trigger because the zabbix's trigger is
              # disabled by zabbix administrator.
            end
          end

          private
          def rpc_request(method, params)
            logger.debug("JSON-RPC Request: #{method}: #{params}")
            res = @json_rpc_connection.request(method, params)
            logger.debug("JSON-RPC Response: #{method}: #{res.json_body}")
            raise res.error_message if res.error?

            res
          end
        end
      end

      # Detects host node failure by checking external monitoring
      # script and trigger evacuation process for instances with HA
      # enabled.
      #
      # monitoring script is expected to return exit code as follows:
      #  success: 0
      #  detected failure: 100
      #  other failure: !0 && !100
      def monitor_host_node_external
        host_node_lst = rpc.request('hva-collector', 'get_external_monitor_target_host_nodes')
        host_node_lst.each { |host_uuid|
          system("#{Dcmgr.conf.instance_ha.monitor_script_path} #{host_uuid}")
          case $?.exitstatus
          when 0
            logger.debug("no failure in #{host_uuid}.")
          when 100
            logger.error("detected #{host_uuid} failure.")
            jobrpc.submit("scheduler", 'evacuate_from',
                          host_uuid, true)
          else
            logger.warn("monitor script is getting something failed.")
          end
        }
      end

      def update_instance_state(inst, opts, ev)
        rpc.request('hva-collector', 'update_instance', inst.canonical_uuid, opts)
        event.publish(ev, :args=>[inst.canonical_uuid])
      end

      def restart_instance(inst)
        # terminate and cleanup

        # set boot_vol before instance is cleaned up.
        case inst.image.boot_dev_type
        when Models::Image::BOOT_DEV_SAN
          boot_vol = inst.volume.find {|v| v.boot_dev == 1 }
        end

        begin
          jobrpc.run("hva-handle.#{inst.host_node.node_id}", 'cleanup', inst.canonical_uuid)
        rescue => e
          # instance termination may fail
        end

        # TODO: pick a new host node
        Isono::NodeModules::DataStore.barrier {
          inst.state = :failingover
          inst.save_changes
        }

        # schedule the location for new instance.
        case inst.image.boot_dev_type
        when Models::Image::BOOT_DEV_SAN
          jobrpc.submit("scheduler", 'schedule_instance_ha', inst.canonical_uuid, boot_vol)
        when Models::Image::BOOT_DEV_LOCAL
          jobrpc.submit("scheduler", 'schedule_instance_ha', inst.canonical_uuid, nil)
        else
          raise "Unknown boot type"
        end

        logger.info("#{inst.canonical_uuid} has been restarted")
      end

      private
      def event
        @event ||= Isono::NodeModules::EventChannel.new(node)
      end

      def jobrpc
        @jobrpc ||= Isono::NodeModules::JobChannel.new(node)
      end

      def rpc
        @rpc ||= Isono::NodeModules::RpcChannel.new(@node)
      end
    end
  end
end
