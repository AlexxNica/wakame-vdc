# -*- coding: utf-8 -*-
require 'isono'

module Dcmgr
  module NodeModules
    class HaManager < Isono::NodeModules::Base
      include Dcmgr::Logger

      initialize_hook do
        @thread_pool = Isono::ThreadPool.new(1, 'HA_Monitor')
        event = Isono::NodeModules::EventChannel.new(node)
        event.subscribe('hva/fault_instance', '#') { |args|
          @thread_pool.pass {
            inst_id = args[0]

            inst = rpc.request('hva-collector', 'get_instance', inst_id)
            # Here may get the event from the instances that no longer
            # exits on the database.
            if inst.nil?
              logger.error("Received fault instance event from unknown instance: #{inst_id}")
              next
            end

            # check if the instance has HA enable.
            if inst.ha_enabled == 0
              next
            else
              myinstance.restart_instance(inst)
            end
          }
        }

        # HostNode failure detection
        if Dcmgr.conf.instance_ha.monitor_script_path
          EM.add_periodic_timer(Dcmgr.conf.instance_ha.monitor_frequency_sec) {
            @thread_pool.pass {
              #myinstance.monitor_host_node_external
            }
          }
        end

        @monitor_target = MonitorTarget.new
        if Dcmgr.conf.monitor_target
          Dcmgr.conf.monitor_target.monitor_items.each { |name, mi|
            @monitor_target.add_monitor_item(name, mi)
          }
        end

        @monitor_target.monitor_items.values.each { |mi|
          EM.add_periodic_timer(mi.poll_wait_sec) {
            @thread_pool.pass {
              myinstance.monitor_host_node_external2(mi)
            }
          }
        }
      end

      terminate_hook do
        @thread_pool.shutdown
      end

      def monitor_host_node_external2(monitor_item)
        host_node_lst = rpc.request('hva-collector', 'get_external_monitor_target_host_nodes')
        host_node_lst.each { |host_uuid|
          monitor_item.poll(host_uuid)
        }
      end

      class MonitorTarget
        attr_reader :monitor_items

        def initialize
          @monitor_items = {}
          @condition = Condition.new
        end

        def add_monitor_item(name, monitor_item)
          if @monitor_items.has_key?(name)
            raise "Duplicate monitor item name: #{name}"
          end
          @monitor_items[name] = monitor_item
          monitor_item.trigger = trigger = Trigger.new(@condition, monitor_item)
          trigger.monitor_item_node.children << @condition.end_node
        end
      end

      class Condition
        attr_reader :end_node

        def initialize
          @end_node = EndNode.new(self)
          @contexts = Hash.new { |h, k| h[k] = ContextStack.new }
        end

        def reset
          @contexts.each { |c| c.reset }
        end

        def apply(host_uuid, start_node, result)
          ctx = @contexts[host_uuid]
          ctx.reset_depth
          start_node.evaluate(result, nil, ctx)
        end

        def process_result(result)
          puts "process_result => #{result}"
        end

        class ContextStack
          def initialize()
            reset
          end

          def reset
            @stack = [{}]
            reset_depth
          end

          def reset_depth
            @depth = 0
          end

          def [](k)
            current[k]
          end

          def []=(k, v)
            current[k] = v
          end

          def push
            @depth += 1
            if @stack.size - 1 <= @depth
              @stack.push({})
            end
            self
          end

          def pop
            raise "Unable to pop " if @depth <= 0
            @depth -= 1
            self
          end

          private
          def current
            @stack[@depth]
          end
        end

        class Node
          attr_reader :children

          def initialize()
            @children = []
          end

          def chain(context, result=:success)
            context.push
            @children.each { |node|
              node.evaluate(result, self, context)
            }
          end

          def reset(context)
          end

          def evaluate(result, parent_node, context)
          end
        end

        class MonitorItemNode < Node
          attr_reader :monitor_item
          
          def initialize(monitor_item)
            super()
            @monitor_item = monitor_item
          end
          
          def evaluate(result, parent_node, context)
            chain(context, result)
          end
        end

        class EndNode < Node
          attr_reader :condition

          def initialize(condition)
            super()
            @condition = condition
          end

          def evaluate(result, parent_node, context)
            @condition.process_result(result)
          end
        end
      end

      class Trigger
        attr_reader :monitor_item_node

        def initialize(condition, monitor_item)
          @condition = condition
          @monitor_item_node = Condition::MonitorItemNode.new(monitor_item)
        end

        def success(host_uuid)
          @condition.apply(host_uuid, @monitor_item_node, :success)
        end

        def failure(host_uuid)
          @condition.apply(host_uuid, @monitor_item_node, :failure)
        end
      end

      class MonitorItem
        attr_reader :poll_wait_sec
        attr_accessor :trigger

        def poll(host_uuid, opts={})
        end

        class Script < MonitorItem
          def initialize(script_path)
            @poll_wait_sec = 3
            @script_path = script_path
          end

          def poll(host_uuid, opts={})
            system("#{@script_path} #{host_uuid}")
            case $?.exitstatus
            when 0
              trigger.success(host_uuid)
            when 100
              trigger.failure(host_uuid)
            else
            end
          end
        end
      end

      # Detects host node failure by checking external monitoring
      # script and trigger evacuation process for instances with HA
      # enabled.
      #
      # monitoring script is expected to return exit code as follows:
      #  success: 0
      #  detected failure: 100
      #  other failure: !0 && !100
      def monitor_host_node_external
        host_node_lst = rpc.request('hva-collector', 'get_external_monitor_target_host_nodes')
        host_node_lst.each { |host_uuid|
          system("#{Dcmgr.conf.instance_ha.monitor_script_path} #{host_uuid}")
          case $?.exitstatus
          when 0
            logger.debug("no failure in #{host_uuid}.")
          when 100
            logger.error("detected #{host_uuid} failure.")
            jobrpc.submit("scheduler", 'evacuate_from',
                          host_uuid, true)
          else
            logger.warn("monitor script is getting something failed.")
          end
        }
      end

      def update_instance_state(inst, opts, ev)
        rpc.request('hva-collector', 'update_instance', inst.canonical_uuid, opts)
        event.publish(ev, :args=>[inst.canonical_uuid])
      end

      def restart_instance(inst)
        # terminate and cleanup

        # set boot_vol before instance is cleaned up.
        case inst.image.boot_dev_type
        when Models::Image::BOOT_DEV_SAN
          boot_vol = inst.volume.find {|v| v.boot_dev == 1 }
        end

        begin
          jobrpc.run("hva-handle.#{inst.host_node.node_id}", 'cleanup', inst.canonical_uuid)
        rescue => e
          # instance termination may fail
        end

        # TODO: pick a new host node
        Isono::NodeModules::DataStore.barrier {
          inst.state = :failingover
          inst.save_changes
        }

        # schedule the location for new instance.
        case inst.image.boot_dev_type
        when Models::Image::BOOT_DEV_SAN
          jobrpc.submit("scheduler", 'schedule_instance_ha', inst.canonical_uuid, boot_vol)
        when Models::Image::BOOT_DEV_LOCAL
          jobrpc.submit("scheduler", 'schedule_instance_ha', inst.canonical_uuid, nil)
        else
          raise "Unknown boot type"
        end

        logger.info("#{inst.canonical_uuid} has been restarted")
      end

      private
      def event
        @event ||= Isono::NodeModules::EventChannel.new(node)
      end

      def jobrpc
        @jobrpc ||= Isono::NodeModules::JobChannel.new(node)
      end

      def rpc
        @rpc ||= Isono::NodeModules::RpcChannel.new(@node)
      end
    end
  end
end
